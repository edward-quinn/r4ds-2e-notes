[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R For Data Science, 2nd Edition Notebook",
    "section": "",
    "text": "R for Data Science, 2nd edition (Wickham, Çetinkaya-Rundel, and Grolemund 2023) can be found here.\n\nChapter 5 Notes\nChapter 12 Notes\nChapter 25 Notes\nChapter 26 Notes\n\n\n\n\n\nReferences\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. 2nd ed. O’Reilly Media."
  },
  {
    "objectID": "chapter_25_notes.html",
    "href": "chapter_25_notes.html",
    "title": "R for Data Science, 2nd Edition - Chapter 25 Notes",
    "section": "",
    "text": "Why use functions?\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\nIt makes it easier to reuse work from project-to-project, increasing your productivity over time.\n\nUse functions when you find yourself repeating your code more than once. Here are the functions we’ll learn about:\n\nVector functions take one or more vectors as input and return a vector as output.\nData frame functions take a data frame as input and return a data frame as output.\nPlot functions that take a data frame as input and return a plot as output.\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(nycflights13)\n\n\n\nHere is an example of a rescaling function.\n\ndf &lt;- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |&gt; mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(a, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(b, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n\n# A tibble: 5 × 4\n       a       b     c     d\n   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1      -0.361  0.859 0.831\n2 0.0980 -0.0264 1     1    \n3 0.765   0.639  0     0    \n4 0       0.181  0.374 0.131\n5 0.529   0.262  0.710 0.589\n\n#&gt; # A tibble: 5 × 4\n#&gt;       a       b     c     d\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339  0.387  0.291 0    \n#&gt; 2 0.880 -0.613  0.611 0.557\n#&gt; 3 0     -0.0833 1     0.752\n#&gt; 4 0.795 -0.0822 0     1    \n#&gt; 5 1     -0.0952 0.580 0.394\n\nHere is the function:\n\nrescale01 &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nNow call the function with mutate for cleaner code:\n\ndf |&gt; mutate(\n  a = rescale01(a),\n  b = rescale01(b),\n  c = rescale01(c),\n  d = rescale01(d),\n)\n\n# A tibble: 5 × 4\n       a     b     c     d\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1      0     0.859 0.831\n2 0.0980 0.335 1     1    \n3 0.765  1     0     0    \n4 0      0.543 0.374 0.131\n5 0.529  0.624 0.710 0.589\n\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339 1     0.291 0    \n#&gt; 2 0.880 0     0.611 0.557\n#&gt; 3 0     0.530 1     0.752\n#&gt; 4 0.795 0.531 0     1    \n#&gt; 5 1     0.518 0.580 0.394\n\nVector functions work well inside of mutate() and filter() return a vector that is the same length as the input vector.\n\nz_score &lt;- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\n\nclamp &lt;- function(x, min, max) {\n  case_when(\n    x &lt; min ~ min,\n    x &gt; max ~ max,\n    .default = x\n  )\n}\n\nclamp(1:10, min = 3, max = 7)\n\n [1] 3 3 3 4 5 6 7 7 7 7\n\n#&gt;  [1] 3 3 3 4 5 6 7 7 7 7\n\n\nfirst_upper &lt;- function(x) {\n  str_sub(x, 1, 1) &lt;- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nfirst_upper(\"hello\")\n\n[1] \"Hello\"\n\n#&gt; [1] \"Hello\"\n\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nclean_number &lt;- function(x) {\n  is_pct &lt;- str_detect(x, \"%\")\n  num &lt;- x |&gt; \n    str_remove_all(\"%\") |&gt; \n    str_remove_all(\",\") |&gt; \n    str_remove_all(fixed(\"$\")) |&gt; \n    as.numeric()\n  if_else(is_pct, num / 100, num)\n}\n\nclean_number(\"$12,300\")\n\n[1] 12300\n\n#&gt; [1] 12300\nclean_number(\"45%\")\n\n[1] 0.45\n\n#&gt; [1] 0.45\n\n\nfix_na &lt;- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\nSummary functions are another important family of functions that return a single value for use in summarize().\n\ncommas &lt;- function(x) {\n  str_flatten(x, collapse = \", \", last = \" and \")\n}\n\ncommas(c(\"cat\", \"dog\", \"pigeon\"))\n\n[1] \"cat, dog and pigeon\"\n\n#&gt; [1] \"cat, dog and pigeon\"\n\n\ncv &lt;- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n\n[1] 0.639585\n\n#&gt; [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n\n[1] 0.5552002\n\n#&gt; [1] 0.5652554\n\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nn_missing &lt;- function(x) {\n  sum(is.na(x))\n} \n\n\n# mean absolute percentage error\n\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nmape &lt;- function(actual, predicted) {\n  sum(abs((actual - predicted) / actual)) / length(actual)\n}\n\n\n\n\nIf copying multiple verbs multiple times, you probably need a data frame function.\nYou will need to deal with the problem of indirection, resulting from tidy evaluation. The solution is to us embracing with { }.\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by(group_var) |&gt; \n    summarize(mean(mean_var))\n}\n\nThe following will error out:\n\n# diamonds |&gt; grouped_mean(cut, carat)\n# #&gt; Error in `group_by()`:\n# #&gt; ! Must group by variables found in `.data`.\n# #&gt; ✖ Column `group_var` is not found.\n\nAn illustration of the problem:\n\ndf &lt;- tibble(\n  mean_var = 1,\n  group_var = \"g\",\n  group = 1,\n  x = 10,\n  y = 100\n)\n\ndf |&gt; grouped_mean(group, x)\n\n# A tibble: 1 × 2\n  group_var `mean(mean_var)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 g                        1\n\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\ndf |&gt; grouped_mean(group, y)\n\n# A tibble: 1 × 2\n  group_var `mean(mean_var)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 g                        1\n\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\n\nWe are returning values, but it is the “mean” of a single value, which is being returned as 1.\nWe need to tell dplyr to run verbs on the values inside of the variable, and not to look for a variable with the argument name. We don’t actually have a variable called mean_var or group_var.\nUse { } to solve this problem.\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by({{ group_var }}) |&gt; \n    summarize(mean({{ mean_var }}))\n}\n\ndf |&gt; grouped_mean(group, x)\n\n# A tibble: 1 × 2\n  group `mean(x)`\n  &lt;dbl&gt;     &lt;dbl&gt;\n1     1        10\n\n#&gt; # A tibble: 1 × 2\n#&gt;   group `mean(x)`\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1        10\n\nWe need to embrace when Data-masking (arrange(), filter(), summarize()) or Tidy-selection (select(), relocate(), rename()) occur.\n\nsummary6 &lt;- function(data, var) {\n  data |&gt; summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    mean = mean({{ var }}, na.rm = TRUE),\n    median = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_miss = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamonds |&gt; summary6(carat)\n\n# A tibble: 1 × 6\n    min  mean median   max     n n_miss\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n1   0.2 0.798    0.7  5.01 53940      0\n\n#&gt; # A tibble: 1 × 6\n#&gt;     min  mean median   max     n n_miss\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1   0.2 0.798    0.7  5.01 53940      0\n\n(Whenever you wrap summarize() in a helper, we think it’s good practice to set .groups = “drop” to both avoid the message and leave the data in an ungrouped state.)\nIf you wrap summarize() within a function, then it can be used on grouped data:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(carat)\n\n# A tibble: 5 × 7\n  cut         min  mean median   max     n n_miss\n  &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n1 Fair       0.22 1.05    1     5.01  1610      0\n2 Good       0.23 0.849   0.82  3.01  4906      0\n3 Very Good  0.2  0.806   0.71  4    12082      0\n4 Premium    0.2  0.892   0.86  4.01 13791      0\n5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\n#&gt; # A tibble: 5 × 7\n#&gt;   cut         min  mean median   max     n n_miss\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair       0.22 1.05    1     5.01  1610      0\n#&gt; 2 Good       0.23 0.849   0.82  3.01  4906      0\n#&gt; 3 Very Good  0.2  0.806   0.71  4    12082      0\n#&gt; 4 Premium    0.2  0.892   0.86  4.01 13791      0\n#&gt; 5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\nFurthermore, since the arguments to summarize are data-masking, so is the var argument to summary6(). That means you can also summarize computed variables:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(log10(carat))\n\n# A tibble: 5 × 7\n  cut          min    mean  median   max     n n_miss\n  &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n1 Fair      -0.658 -0.0273  0      0.700  1610      0\n2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\n#&gt; # A tibble: 5 × 7\n#&gt;   cut          min    mean  median   max     n n_miss\n#&gt;   &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair      -0.658 -0.0273  0      0.700  1610      0\n#&gt; 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n#&gt; 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n#&gt; 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n#&gt; 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\nTo summarize multiple variables, use across().\nHere’s a version of count that also calculates proportions.\n\n# https://twitter.com/Diabb6/status/1571635146658402309\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}\n\ndiamonds |&gt; count_prop(clarity)\n\n# A tibble: 8 × 3\n  clarity     n   prop\n  &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n1 I1        741 0.0137\n2 SI2      9194 0.170 \n3 SI1     13065 0.242 \n4 VS2     12258 0.227 \n5 VS1      8171 0.151 \n6 VVS2     5066 0.0939\n7 VVS1     3655 0.0678\n8 IF       1790 0.0332\n\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity     n   prop\n#&gt;   &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 I1        741 0.0137\n#&gt; 2 SI2      9194 0.170 \n#&gt; 3 SI1     13065 0.242 \n#&gt; 4 VS2     12258 0.227 \n#&gt; 5 VS1      8171 0.151 \n#&gt; 6 VVS2     5066 0.0939\n#&gt; # ℹ 2 more rows\n\nFinding sorted unique values of a subset of the data:\n\nunique_where &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    distinct({{ var }}) |&gt; \n    arrange({{ var }})\n}\n\n# Find all the destinations in December\nflights |&gt; unique_where(month == 12, dest)\n\n# A tibble: 96 × 1\n   dest \n   &lt;chr&gt;\n 1 ABQ  \n 2 ALB  \n 3 ATL  \n 4 AUS  \n 5 AVL  \n 6 BDL  \n 7 BGR  \n 8 BHM  \n 9 BNA  \n10 BOS  \n# ℹ 86 more rows\n\n#&gt; # A tibble: 96 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 ABQ  \n#&gt; 2 ALB  \n#&gt; 3 ATL  \n#&gt; 4 AUS  \n#&gt; 5 AVL  \n#&gt; 6 BDL  \n#&gt; # ℹ 90 more rows\n\nData-masking vs. tidy-selection\n\n\n\n\n\n\n\n\n\n\nSituation\nWhat you have\nWhat you want\nUse this\nExample\n\n\n\n\nColumn passed as bare name\ncol\nUse column values\n{ col }\nfilter(df, {{ col }} &gt; 0)\n\n\nColumn name as string\n\"col\"\nUse column values\n.data[[col]]\nfilter(df, .data[[col]] &gt; 0)\n\n\nColumn passed bare\ncols\nSelect columns\n{ cols }\nselect(df, {{ cols }})\n\n\nVector of column names\nc(\"a\",\"b\")\nSelect columns\nall_of()\nselect(df, all_of(cols))\n\n\nOptional columns\nc(\"a\",\"b\")\nSelect if present\nany_of()\nselect(df, any_of(cols))\n\n\nApply function to columns\ntidy-select\nMultiple columns\nacross()\nmutate(df, across({{ cols }}, mean))\n\n\nProgramming w/ quosures\nexpression\nFull NSE control\nenquo() / !!\nfilter(df, !!q &gt; 0)\n\n\nMix columns + env vars\nboth\nAvoid name clash\n.data / .env\nfilter(df, x &gt; .env$cutoff)\n\n\n\nWhat if you want to select variables inside of a function that uses data-masking? The following will not work:\n\n# count_missing &lt;- function(df, group_vars, x_var) {\n#   df |&gt; \n#     group_by({{ group_vars }}) |&gt; # this is a problem. group_by uses data masking, not tidy selection.\n#     summarize(\n#       n_miss = sum(is.na({{ x_var }})), \n#       .groups = \"drop\"\n#     )\n# }\n# \n# flights |&gt; \n#   count_missing(c(year, month, day), dep_time)\n#&gt; Error in `group_by()`:\n#&gt; ℹ In argument: `c(year, month, day)`.\n#&gt; Caused by error:\n#&gt; ! `c(year, month, day)` must be size 336776 or 1, not 1010328.\n\nUse the pick() function for tidy selection inside of a data masking function.\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n  )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n\n# A tibble: 365 × 4\n    year month   day n_miss\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n 1  2013     1     1      4\n 2  2013     1     2      8\n 3  2013     1     3     10\n 4  2013     1     4      6\n 5  2013     1     5      3\n 6  2013     1     6      1\n 7  2013     1     7      3\n 8  2013     1     8      4\n 9  2013     1     9      5\n10  2013     1    10      3\n# ℹ 355 more rows\n\n#&gt; # A tibble: 365 × 4\n#&gt;    year month   day n_miss\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1  2013     1     1      4\n#&gt; 2  2013     1     2      8\n#&gt; 3  2013     1     3     10\n#&gt; 4  2013     1     4      6\n#&gt; 5  2013     1     5      3\n#&gt; 6  2013     1     6      1\n#&gt; # ℹ 359 more rows\n\n\n# https://twitter.com/pollicipes/status/1571606508944719876\ncount_wide &lt;- function(data, rows, cols) {\n  data |&gt; \n    count(pick(c({{ rows }}, {{ cols }}))) |&gt; \n    pivot_wider(\n      names_from = {{ cols }}, # names_from uses tidy selection\n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamonds |&gt; count_wide(c(clarity, color), cut)\n\n# A tibble: 56 × 7\n   clarity color  Fair  Good `Very Good` Premium Ideal\n   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n 1 I1      D         4     8           5      12    13\n 2 I1      E         9    23          22      30    18\n 3 I1      F        35    19          13      34    42\n 4 I1      G        53    19          16      46    16\n 5 I1      H        52    14          12      46    38\n 6 I1      I        34     9           8      24    17\n 7 I1      J        23     4           8      13     2\n 8 SI2     D        56   223         314     421   356\n 9 SI2     E        78   202         445     519   469\n10 SI2     F        89   201         343     523   453\n# ℹ 46 more rows\n\n#&gt; # A tibble: 56 × 7\n#&gt;   clarity color  Fair  Good `Very Good` Premium Ideal\n#&gt;   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 I1      D         4     8           5      12    13\n#&gt; 2 I1      E         9    23          22      30    18\n#&gt; 3 I1      F        35    19          13      34    42\n#&gt; 4 I1      G        53    19          16      46    16\n#&gt; 5 I1      H        52    14          12      46    38\n#&gt; 6 I1      I        34     9           8      24    17\n#&gt; # ℹ 50 more rows\n\n\n\n\nInstead of returning a dataframe, you can return a plot from a function. ggplot2::aes() is a data-masking function.\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.05)\n\n\n\n\n\n\n\n\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\n\nBecause a ggplot2 object is returned, you can add on additional components with +.\n\ndiamonds |&gt; \n  histogram(carat, 0.1) +\n  labs(x = \"Size (in carats)\", y = \"Number of diamonds\")\n\n\n\n\n\n\n\n\nAdding more variables\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nlinearity_check &lt;- function(df, x, y) {\n  df |&gt;\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\nstarwars |&gt; \n  filter(mass &lt; 1000) |&gt; \n  linearity_check(mass, height)\n\n\n\n\n\n\n\n\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\nhex_plot &lt;- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |&gt; \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # make border same color as fill\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamonds |&gt; hex_plot(carat, price, depth)\n\n\n\n\n\n\n\n\nCombining ggplot with other tidyverse\nSorted bar chart function\n\nsorted_bars &lt;- function(df, var) {\n  df |&gt; \n    # note the walrus operator here\n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |&gt; \n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamonds |&gt; sorted_bars(clarity)\n\n\n\n\n\n\n\n\nConditional plot functions\n\nconditional_bars &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamonds |&gt; conditional_bars(cut == \"Good\", clarity)\n\n\n\n\n\n\n\n\nLabeling the plots you create\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\nWhat if we could label the plot with the variable and binwidth used?\nUse rlang::englue() for this\n\nhistogram &lt;- function(df, var, binwidth) {\n  label &lt;- rlang::englue(\"A histogram of {{var}} with binwidth {binwidth}\")\n  \n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = label)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)"
  },
  {
    "objectID": "chapter_25_notes.html#vector-functions",
    "href": "chapter_25_notes.html#vector-functions",
    "title": "R for Data Science, 2nd Edition - Chapter 25 Notes",
    "section": "",
    "text": "Here is an example of a rescaling function.\n\ndf &lt;- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |&gt; mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(a, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(b, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n\n# A tibble: 5 × 4\n       a       b     c     d\n   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1      -0.361  0.859 0.831\n2 0.0980 -0.0264 1     1    \n3 0.765   0.639  0     0    \n4 0       0.181  0.374 0.131\n5 0.529   0.262  0.710 0.589\n\n#&gt; # A tibble: 5 × 4\n#&gt;       a       b     c     d\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339  0.387  0.291 0    \n#&gt; 2 0.880 -0.613  0.611 0.557\n#&gt; 3 0     -0.0833 1     0.752\n#&gt; 4 0.795 -0.0822 0     1    \n#&gt; 5 1     -0.0952 0.580 0.394\n\nHere is the function:\n\nrescale01 &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nNow call the function with mutate for cleaner code:\n\ndf |&gt; mutate(\n  a = rescale01(a),\n  b = rescale01(b),\n  c = rescale01(c),\n  d = rescale01(d),\n)\n\n# A tibble: 5 × 4\n       a     b     c     d\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1      0     0.859 0.831\n2 0.0980 0.335 1     1    \n3 0.765  1     0     0    \n4 0      0.543 0.374 0.131\n5 0.529  0.624 0.710 0.589\n\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339 1     0.291 0    \n#&gt; 2 0.880 0     0.611 0.557\n#&gt; 3 0     0.530 1     0.752\n#&gt; 4 0.795 0.531 0     1    \n#&gt; 5 1     0.518 0.580 0.394\n\nVector functions work well inside of mutate() and filter() return a vector that is the same length as the input vector.\n\nz_score &lt;- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\n\nclamp &lt;- function(x, min, max) {\n  case_when(\n    x &lt; min ~ min,\n    x &gt; max ~ max,\n    .default = x\n  )\n}\n\nclamp(1:10, min = 3, max = 7)\n\n [1] 3 3 3 4 5 6 7 7 7 7\n\n#&gt;  [1] 3 3 3 4 5 6 7 7 7 7\n\n\nfirst_upper &lt;- function(x) {\n  str_sub(x, 1, 1) &lt;- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nfirst_upper(\"hello\")\n\n[1] \"Hello\"\n\n#&gt; [1] \"Hello\"\n\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nclean_number &lt;- function(x) {\n  is_pct &lt;- str_detect(x, \"%\")\n  num &lt;- x |&gt; \n    str_remove_all(\"%\") |&gt; \n    str_remove_all(\",\") |&gt; \n    str_remove_all(fixed(\"$\")) |&gt; \n    as.numeric()\n  if_else(is_pct, num / 100, num)\n}\n\nclean_number(\"$12,300\")\n\n[1] 12300\n\n#&gt; [1] 12300\nclean_number(\"45%\")\n\n[1] 0.45\n\n#&gt; [1] 0.45\n\n\nfix_na &lt;- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\nSummary functions are another important family of functions that return a single value for use in summarize().\n\ncommas &lt;- function(x) {\n  str_flatten(x, collapse = \", \", last = \" and \")\n}\n\ncommas(c(\"cat\", \"dog\", \"pigeon\"))\n\n[1] \"cat, dog and pigeon\"\n\n#&gt; [1] \"cat, dog and pigeon\"\n\n\ncv &lt;- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n\n[1] 0.639585\n\n#&gt; [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n\n[1] 0.5552002\n\n#&gt; [1] 0.5652554\n\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nn_missing &lt;- function(x) {\n  sum(is.na(x))\n} \n\n\n# mean absolute percentage error\n\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nmape &lt;- function(actual, predicted) {\n  sum(abs((actual - predicted) / actual)) / length(actual)\n}"
  },
  {
    "objectID": "chapter_25_notes.html#data-frame-functions",
    "href": "chapter_25_notes.html#data-frame-functions",
    "title": "R for Data Science, 2nd Edition - Chapter 25 Notes",
    "section": "",
    "text": "If copying multiple verbs multiple times, you probably need a data frame function.\nYou will need to deal with the problem of indirection, resulting from tidy evaluation. The solution is to us embracing with { }.\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by(group_var) |&gt; \n    summarize(mean(mean_var))\n}\n\nThe following will error out:\n\n# diamonds |&gt; grouped_mean(cut, carat)\n# #&gt; Error in `group_by()`:\n# #&gt; ! Must group by variables found in `.data`.\n# #&gt; ✖ Column `group_var` is not found.\n\nAn illustration of the problem:\n\ndf &lt;- tibble(\n  mean_var = 1,\n  group_var = \"g\",\n  group = 1,\n  x = 10,\n  y = 100\n)\n\ndf |&gt; grouped_mean(group, x)\n\n# A tibble: 1 × 2\n  group_var `mean(mean_var)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 g                        1\n\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\ndf |&gt; grouped_mean(group, y)\n\n# A tibble: 1 × 2\n  group_var `mean(mean_var)`\n  &lt;chr&gt;                &lt;dbl&gt;\n1 g                        1\n\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\n\nWe are returning values, but it is the “mean” of a single value, which is being returned as 1.\nWe need to tell dplyr to run verbs on the values inside of the variable, and not to look for a variable with the argument name. We don’t actually have a variable called mean_var or group_var.\nUse { } to solve this problem.\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by({{ group_var }}) |&gt; \n    summarize(mean({{ mean_var }}))\n}\n\ndf |&gt; grouped_mean(group, x)\n\n# A tibble: 1 × 2\n  group `mean(x)`\n  &lt;dbl&gt;     &lt;dbl&gt;\n1     1        10\n\n#&gt; # A tibble: 1 × 2\n#&gt;   group `mean(x)`\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1        10\n\nWe need to embrace when Data-masking (arrange(), filter(), summarize()) or Tidy-selection (select(), relocate(), rename()) occur.\n\nsummary6 &lt;- function(data, var) {\n  data |&gt; summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    mean = mean({{ var }}, na.rm = TRUE),\n    median = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_miss = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamonds |&gt; summary6(carat)\n\n# A tibble: 1 × 6\n    min  mean median   max     n n_miss\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n1   0.2 0.798    0.7  5.01 53940      0\n\n#&gt; # A tibble: 1 × 6\n#&gt;     min  mean median   max     n n_miss\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1   0.2 0.798    0.7  5.01 53940      0\n\n(Whenever you wrap summarize() in a helper, we think it’s good practice to set .groups = “drop” to both avoid the message and leave the data in an ungrouped state.)\nIf you wrap summarize() within a function, then it can be used on grouped data:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(carat)\n\n# A tibble: 5 × 7\n  cut         min  mean median   max     n n_miss\n  &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n1 Fair       0.22 1.05    1     5.01  1610      0\n2 Good       0.23 0.849   0.82  3.01  4906      0\n3 Very Good  0.2  0.806   0.71  4    12082      0\n4 Premium    0.2  0.892   0.86  4.01 13791      0\n5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\n#&gt; # A tibble: 5 × 7\n#&gt;   cut         min  mean median   max     n n_miss\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair       0.22 1.05    1     5.01  1610      0\n#&gt; 2 Good       0.23 0.849   0.82  3.01  4906      0\n#&gt; 3 Very Good  0.2  0.806   0.71  4    12082      0\n#&gt; 4 Premium    0.2  0.892   0.86  4.01 13791      0\n#&gt; 5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\nFurthermore, since the arguments to summarize are data-masking, so is the var argument to summary6(). That means you can also summarize computed variables:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(log10(carat))\n\n# A tibble: 5 × 7\n  cut          min    mean  median   max     n n_miss\n  &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n1 Fair      -0.658 -0.0273  0      0.700  1610      0\n2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\n#&gt; # A tibble: 5 × 7\n#&gt;   cut          min    mean  median   max     n n_miss\n#&gt;   &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair      -0.658 -0.0273  0      0.700  1610      0\n#&gt; 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n#&gt; 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n#&gt; 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n#&gt; 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\nTo summarize multiple variables, use across().\nHere’s a version of count that also calculates proportions.\n\n# https://twitter.com/Diabb6/status/1571635146658402309\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}\n\ndiamonds |&gt; count_prop(clarity)\n\n# A tibble: 8 × 3\n  clarity     n   prop\n  &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n1 I1        741 0.0137\n2 SI2      9194 0.170 \n3 SI1     13065 0.242 \n4 VS2     12258 0.227 \n5 VS1      8171 0.151 \n6 VVS2     5066 0.0939\n7 VVS1     3655 0.0678\n8 IF       1790 0.0332\n\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity     n   prop\n#&gt;   &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 I1        741 0.0137\n#&gt; 2 SI2      9194 0.170 \n#&gt; 3 SI1     13065 0.242 \n#&gt; 4 VS2     12258 0.227 \n#&gt; 5 VS1      8171 0.151 \n#&gt; 6 VVS2     5066 0.0939\n#&gt; # ℹ 2 more rows\n\nFinding sorted unique values of a subset of the data:\n\nunique_where &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    distinct({{ var }}) |&gt; \n    arrange({{ var }})\n}\n\n# Find all the destinations in December\nflights |&gt; unique_where(month == 12, dest)\n\n# A tibble: 96 × 1\n   dest \n   &lt;chr&gt;\n 1 ABQ  \n 2 ALB  \n 3 ATL  \n 4 AUS  \n 5 AVL  \n 6 BDL  \n 7 BGR  \n 8 BHM  \n 9 BNA  \n10 BOS  \n# ℹ 86 more rows\n\n#&gt; # A tibble: 96 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 ABQ  \n#&gt; 2 ALB  \n#&gt; 3 ATL  \n#&gt; 4 AUS  \n#&gt; 5 AVL  \n#&gt; 6 BDL  \n#&gt; # ℹ 90 more rows\n\nData-masking vs. tidy-selection\n\n\n\n\n\n\n\n\n\n\nSituation\nWhat you have\nWhat you want\nUse this\nExample\n\n\n\n\nColumn passed as bare name\ncol\nUse column values\n{ col }\nfilter(df, {{ col }} &gt; 0)\n\n\nColumn name as string\n\"col\"\nUse column values\n.data[[col]]\nfilter(df, .data[[col]] &gt; 0)\n\n\nColumn passed bare\ncols\nSelect columns\n{ cols }\nselect(df, {{ cols }})\n\n\nVector of column names\nc(\"a\",\"b\")\nSelect columns\nall_of()\nselect(df, all_of(cols))\n\n\nOptional columns\nc(\"a\",\"b\")\nSelect if present\nany_of()\nselect(df, any_of(cols))\n\n\nApply function to columns\ntidy-select\nMultiple columns\nacross()\nmutate(df, across({{ cols }}, mean))\n\n\nProgramming w/ quosures\nexpression\nFull NSE control\nenquo() / !!\nfilter(df, !!q &gt; 0)\n\n\nMix columns + env vars\nboth\nAvoid name clash\n.data / .env\nfilter(df, x &gt; .env$cutoff)\n\n\n\nWhat if you want to select variables inside of a function that uses data-masking? The following will not work:\n\n# count_missing &lt;- function(df, group_vars, x_var) {\n#   df |&gt; \n#     group_by({{ group_vars }}) |&gt; # this is a problem. group_by uses data masking, not tidy selection.\n#     summarize(\n#       n_miss = sum(is.na({{ x_var }})), \n#       .groups = \"drop\"\n#     )\n# }\n# \n# flights |&gt; \n#   count_missing(c(year, month, day), dep_time)\n#&gt; Error in `group_by()`:\n#&gt; ℹ In argument: `c(year, month, day)`.\n#&gt; Caused by error:\n#&gt; ! `c(year, month, day)` must be size 336776 or 1, not 1010328.\n\nUse the pick() function for tidy selection inside of a data masking function.\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n  )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n\n# A tibble: 365 × 4\n    year month   day n_miss\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n 1  2013     1     1      4\n 2  2013     1     2      8\n 3  2013     1     3     10\n 4  2013     1     4      6\n 5  2013     1     5      3\n 6  2013     1     6      1\n 7  2013     1     7      3\n 8  2013     1     8      4\n 9  2013     1     9      5\n10  2013     1    10      3\n# ℹ 355 more rows\n\n#&gt; # A tibble: 365 × 4\n#&gt;    year month   day n_miss\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1  2013     1     1      4\n#&gt; 2  2013     1     2      8\n#&gt; 3  2013     1     3     10\n#&gt; 4  2013     1     4      6\n#&gt; 5  2013     1     5      3\n#&gt; 6  2013     1     6      1\n#&gt; # ℹ 359 more rows\n\n\n# https://twitter.com/pollicipes/status/1571606508944719876\ncount_wide &lt;- function(data, rows, cols) {\n  data |&gt; \n    count(pick(c({{ rows }}, {{ cols }}))) |&gt; \n    pivot_wider(\n      names_from = {{ cols }}, # names_from uses tidy selection\n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamonds |&gt; count_wide(c(clarity, color), cut)\n\n# A tibble: 56 × 7\n   clarity color  Fair  Good `Very Good` Premium Ideal\n   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n 1 I1      D         4     8           5      12    13\n 2 I1      E         9    23          22      30    18\n 3 I1      F        35    19          13      34    42\n 4 I1      G        53    19          16      46    16\n 5 I1      H        52    14          12      46    38\n 6 I1      I        34     9           8      24    17\n 7 I1      J        23     4           8      13     2\n 8 SI2     D        56   223         314     421   356\n 9 SI2     E        78   202         445     519   469\n10 SI2     F        89   201         343     523   453\n# ℹ 46 more rows\n\n#&gt; # A tibble: 56 × 7\n#&gt;   clarity color  Fair  Good `Very Good` Premium Ideal\n#&gt;   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 I1      D         4     8           5      12    13\n#&gt; 2 I1      E         9    23          22      30    18\n#&gt; 3 I1      F        35    19          13      34    42\n#&gt; 4 I1      G        53    19          16      46    16\n#&gt; 5 I1      H        52    14          12      46    38\n#&gt; 6 I1      I        34     9           8      24    17\n#&gt; # ℹ 50 more rows"
  },
  {
    "objectID": "chapter_25_notes.html#plot-functions",
    "href": "chapter_25_notes.html#plot-functions",
    "title": "R for Data Science, 2nd Edition - Chapter 25 Notes",
    "section": "",
    "text": "Instead of returning a dataframe, you can return a plot from a function. ggplot2::aes() is a data-masking function.\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.05)\n\n\n\n\n\n\n\n\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\n\n\n\n\nBecause a ggplot2 object is returned, you can add on additional components with +.\n\ndiamonds |&gt; \n  histogram(carat, 0.1) +\n  labs(x = \"Size (in carats)\", y = \"Number of diamonds\")\n\n\n\n\n\n\n\n\nAdding more variables\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nlinearity_check &lt;- function(df, x, y) {\n  df |&gt;\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\nstarwars |&gt; \n  filter(mass &lt; 1000) |&gt; \n  linearity_check(mass, height)\n\n\n\n\n\n\n\n\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\nhex_plot &lt;- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |&gt; \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # make border same color as fill\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamonds |&gt; hex_plot(carat, price, depth)\n\n\n\n\n\n\n\n\nCombining ggplot with other tidyverse\nSorted bar chart function\n\nsorted_bars &lt;- function(df, var) {\n  df |&gt; \n    # note the walrus operator here\n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |&gt; \n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamonds |&gt; sorted_bars(clarity)\n\n\n\n\n\n\n\n\nConditional plot functions\n\nconditional_bars &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamonds |&gt; conditional_bars(cut == \"Good\", clarity)\n\n\n\n\n\n\n\n\nLabeling the plots you create\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\nWhat if we could label the plot with the variable and binwidth used?\nUse rlang::englue() for this\n\nhistogram &lt;- function(df, var, binwidth) {\n  label &lt;- rlang::englue(\"A histogram of {{var}} with binwidth {binwidth}\")\n  \n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = label)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)"
  },
  {
    "objectID": "chapter_05_notes.html",
    "href": "chapter_05_notes.html",
    "title": "R for Data Science, 2nd Edition - Chapter 5 Notes",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nUse pivot_longer().\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\"\n  )\n\n# A tibble: 24,092 × 5\n   artist track                   date.entered week   rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n# ℹ 24,082 more rows\n\n#&gt; # A tibble: 24,092 × 5\n#&gt;    artist track                   date.entered week   rank\n#&gt;    &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt;  1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt;  2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt;  3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt;  4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt;  5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt;  6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt;  7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n#&gt;  8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n#&gt;  9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n#&gt; 10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n#&gt; # ℹ 24,082 more rows\n\n\ncols specifies which columns need to be pivoted, i.e. which columns aren’t variables. This argument uses the same syntax as select() so here we could use !c(artist, track, date.entered) or starts_with(\"wk\").\nnames_to names the variable stored in the column names, we named that variable week.\nvalues_to names the variable stored in the cell values, we named that variable rank.\n\nSo pivot_longer() starts with identifying which columns are variables, and which are not. For those columns that are not variables, we create a single variable capturing the names of these non-variable columns, and another variable capturing the values in the cells of those non-variable columns, which we must also name.\nSome NA values may be generated by the structure of the data set. This can be avoided with values_drop_na = TRUE.\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  )\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered week   rank\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87\n10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92\n# ℹ 5,297 more rows\n\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered week   rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt; # ℹ 5,301 more rows\n\nThe values for week are characters. This is a good opportunity to use parse_number().\n\nbillboard_longer &lt;- billboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  ) |&gt; \n  mutate(\n    week = parse_number(week)\n  )\nbillboard_longer\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered  week  rank\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26       1    87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26       2    82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26       3    72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26       4    77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26       5    87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26       6    94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26       7    99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02       1    91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02       2    87\n10 2Ge+her The Hardest Part Of ... 2000-09-02       3    92\n# ℹ 5,297 more rows\n\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered  week  rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26       1    87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26       2    82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26       3    72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26       4    77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26       5    87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26       6    94\n#&gt; # ℹ 5,301 more rows\n\nExamining pivot_longer()\n\ndf &lt;- tribble(\n  ~id,  ~bp1, ~bp2,\n   \"A\",  100,  120,\n   \"B\",  140,  115,\n   \"C\",  120,  125\n)\n\ndf |&gt; \n  pivot_longer(\n    cols = bp1:bp2,\n    names_to = \"measurement\",\n    values_to = \"value\"\n  )\n\n# A tibble: 6 × 3\n  id    measurement value\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 A     bp1           100\n2 A     bp2           120\n3 B     bp1           140\n4 B     bp2           115\n5 C     bp1           120\n6 C     bp2           125\n\n#&gt; # A tibble: 6 × 3\n#&gt;   id    measurement value\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 A     bp1           100\n#&gt; 2 A     bp2           120\n#&gt; 3 B     bp1           140\n#&gt; 4 B     bp2           115\n#&gt; 5 C     bp1           120\n#&gt; 6 C     bp2           125\n\nWhat if column names contain multiple pieces of information?\n\nwho2\n\n# A tibble: 7,240 × 58\n   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554 sp_m_5564\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan  1980       NA        NA        NA        NA        NA        NA\n 2 Afghanistan  1981       NA        NA        NA        NA        NA        NA\n 3 Afghanistan  1982       NA        NA        NA        NA        NA        NA\n 4 Afghanistan  1983       NA        NA        NA        NA        NA        NA\n 5 Afghanistan  1984       NA        NA        NA        NA        NA        NA\n 6 Afghanistan  1985       NA        NA        NA        NA        NA        NA\n 7 Afghanistan  1986       NA        NA        NA        NA        NA        NA\n 8 Afghanistan  1987       NA        NA        NA        NA        NA        NA\n 9 Afghanistan  1988       NA        NA        NA        NA        NA        NA\n10 Afghanistan  1989       NA        NA        NA        NA        NA        NA\n# ℹ 7,230 more rows\n# ℹ 50 more variables: sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, sp_f_1524 &lt;dbl&gt;,\n#   sp_f_2534 &lt;dbl&gt;, sp_f_3544 &lt;dbl&gt;, sp_f_4554 &lt;dbl&gt;, sp_f_5564 &lt;dbl&gt;,\n#   sp_f_65 &lt;dbl&gt;, sn_m_014 &lt;dbl&gt;, sn_m_1524 &lt;dbl&gt;, sn_m_2534 &lt;dbl&gt;,\n#   sn_m_3544 &lt;dbl&gt;, sn_m_4554 &lt;dbl&gt;, sn_m_5564 &lt;dbl&gt;, sn_m_65 &lt;dbl&gt;,\n#   sn_f_014 &lt;dbl&gt;, sn_f_1524 &lt;dbl&gt;, sn_f_2534 &lt;dbl&gt;, sn_f_3544 &lt;dbl&gt;,\n#   sn_f_4554 &lt;dbl&gt;, sn_f_5564 &lt;dbl&gt;, sn_f_65 &lt;dbl&gt;, ep_m_014 &lt;dbl&gt;, …\n\n#&gt; # A tibble: 7,240 × 58\n#&gt;   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980       NA        NA        NA        NA        NA\n#&gt; 2 Afghanistan  1981       NA        NA        NA        NA        NA\n#&gt; 3 Afghanistan  1982       NA        NA        NA        NA        NA\n#&gt; 4 Afghanistan  1983       NA        NA        NA        NA        NA\n#&gt; 5 Afghanistan  1984       NA        NA        NA        NA        NA\n#&gt; 6 Afghanistan  1985       NA        NA        NA        NA        NA\n#&gt; # ℹ 7,234 more rows\n#&gt; # ℹ 51 more variables: sp_m_5564 &lt;dbl&gt;, sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, …\n\nSo in this case we have six pieces of information recorded in who2: the country and the year (already columns); the method of diagnosis, the gender category, and the age range category (contained in the other column names); and the count of patients in that category (cell values).\n\nwho2 |&gt; \n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"), \n    names_sep = \"_\",\n    values_to = \"count\"\n  )\n\n# A tibble: 405,440 × 6\n   country      year diagnosis gender age   count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n 1 Afghanistan  1980 sp        m      014      NA\n 2 Afghanistan  1980 sp        m      1524     NA\n 3 Afghanistan  1980 sp        m      2534     NA\n 4 Afghanistan  1980 sp        m      3544     NA\n 5 Afghanistan  1980 sp        m      4554     NA\n 6 Afghanistan  1980 sp        m      5564     NA\n 7 Afghanistan  1980 sp        m      65       NA\n 8 Afghanistan  1980 sp        f      014      NA\n 9 Afghanistan  1980 sp        f      1524     NA\n10 Afghanistan  1980 sp        f      2534     NA\n# ℹ 405,430 more rows\n\n#&gt; # A tibble: 405,440 × 6\n#&gt;   country      year diagnosis gender age   count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980 sp        m      014      NA\n#&gt; 2 Afghanistan  1980 sp        m      1524     NA\n#&gt; 3 Afghanistan  1980 sp        m      2534     NA\n#&gt; 4 Afghanistan  1980 sp        m      3544     NA\n#&gt; 5 Afghanistan  1980 sp        m      4554     NA\n#&gt; 6 Afghanistan  1980 sp        m      5564     NA\n#&gt; # ℹ 405,434 more rows\n\nWhat if the column names include a mix of of variable values and variable names?\n\nhousehold\n\n# A tibble: 5 × 5\n  family dob_child1 dob_child2 name_child1 name_child2\n   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      \n1      1 1998-11-26 2000-01-29 Susan       Jose       \n2      2 1996-06-22 NA         Mark        &lt;NA&gt;       \n3      3 2002-07-11 2004-04-05 Sam         Seth       \n4      4 2004-10-10 2009-08-27 Craig       Khai       \n5      5 2000-12-05 2005-02-28 Parker      Gracie     \n\n\nUse the .value sentinel value to indicate the first component of the pivoted column name as a variable name in the output. Note the lack of a values_to argument here. When you use .value in names_to, the column names in the input contribute to both values and variable names in the output.\n\nhousehold |&gt; \n  pivot_longer(\n    cols = !family, \n    names_to = c(\".value\", \"child\"), \n    names_sep = \"_\", \n    values_drop_na = TRUE\n  )\n\n# A tibble: 9 × 4\n  family child  dob        name  \n   &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt; \n1      1 child1 1998-11-26 Susan \n2      1 child2 2000-01-29 Jose  \n3      2 child1 1996-06-22 Mark  \n4      3 child1 2002-07-11 Sam   \n5      3 child2 2004-04-05 Seth  \n6      4 child1 2004-10-10 Craig \n7      4 child2 2009-08-27 Khai  \n8      5 child1 2000-12-05 Parker\n9      5 child2 2005-02-28 Gracie\n\n#&gt; # A tibble: 9 × 4\n#&gt;   family child  dob        name \n#&gt;    &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;\n#&gt; 1      1 child1 1998-11-26 Susan\n#&gt; 2      1 child2 2000-01-29 Jose \n#&gt; 3      2 child1 1996-06-22 Mark \n#&gt; 4      3 child1 2002-07-11 Sam  \n#&gt; 5      3 child2 2004-04-05 Seth \n#&gt; 6      4 child1 2004-10-10 Craig\n#&gt; # ℹ 3 more rows\n\n\n\n\nUse pivot_wider() to increase columns and reduce rows.\n\ncms_patient_experience |&gt; \n  distinct(measure_cd, measure_title)\n\n# A tibble: 6 × 2\n  measure_cd   measure_title                                                    \n  &lt;chr&gt;        &lt;chr&gt;                                                            \n1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and Infor…\n2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate               \n3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider                 \n4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education               \n5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff           \n6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources             \n\n#&gt; # A tibble: 6 × 2\n#&gt;   measure_cd   measure_title                                                 \n#&gt;   &lt;chr&gt;        &lt;chr&gt;                                                         \n#&gt; 1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and In…\n#&gt; 2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate            \n#&gt; 3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider              \n#&gt; 4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education            \n#&gt; 5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff        \n#&gt; 6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources\n\npivot_wider() has the opposite interface to pivot_longer(): instead of choosing new column names, we need to provide the existing columns that define the values (values_from) and the column name (names_from):\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n\n# A tibble: 500 × 9\n   org_pac_id org_nm           measure_title CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 0446157747 USC CARE MEDICA… CAHPS for MI…          63          NA          NA\n 2 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          87          NA\n 3 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          86\n 4 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          NA\n 5 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          NA\n 6 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          NA\n 7 0446162697 ASSOCIATION OF … CAHPS for MI…          59          NA          NA\n 8 0446162697 ASSOCIATION OF … CAHPS for MI…          NA          85          NA\n 9 0446162697 ASSOCIATION OF … CAHPS for MI…          NA          NA          83\n10 0446162697 ASSOCIATION OF … CAHPS for MI…          NA          NA          NA\n# ℹ 490 more rows\n# ℹ 3 more variables: CAHPS_GRP_5 &lt;dbl&gt;, CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\n#&gt; # A tibble: 500 × 9\n#&gt;   org_pac_id org_nm                   measure_title   CAHPS_GRP_1 CAHPS_GRP_2\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                    &lt;chr&gt;                 &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          63          NA\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; # ℹ 494 more rows\n#&gt; # ℹ 4 more variables: CAHPS_GRP_3 &lt;dbl&gt;, CAHPS_GRP_5 &lt;dbl&gt;, …\n\nIf you still have multiple rows per unit of interest, organization in this case, then the pivot_wider() didn’t work.\nThe problem is we need to tell pivot_wider() which column or columns have values that uniquely identify each row, in this case those are the variables starting with \"org\":\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    id_cols = starts_with(\"org\"),\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n\n# A tibble: 95 × 8\n   org_pac_id org_nm CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5 CAHPS_GRP_8\n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 0446157747 USC C…          63          87          86          57          85\n 2 0446162697 ASSOC…          59          85          83          63          88\n 3 0547164295 BEAVE…          49          NA          75          44          73\n 4 0749333730 CAPE …          67          84          85          65          82\n 5 0840104360 ALLIA…          66          87          87          64          87\n 6 0840109864 REX H…          73          87          84          67          91\n 7 0840513552 SCL H…          58          83          76          58          78\n 8 0941545784 GRITM…          46          86          81          54          NA\n 9 1052612785 COMMU…          65          84          80          58          87\n10 1254237779 OUR L…          61          NA          NA          65          NA\n# ℹ 85 more rows\n# ℹ 1 more variable: CAHPS_GRP_12 &lt;dbl&gt;\n\n#&gt; # A tibble: 95 × 8\n#&gt;   org_pac_id org_nm           CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICA…          63          87          86          57\n#&gt; 2 0446162697 ASSOCIATION OF …          59          85          83          63\n#&gt; 3 0547164295 BEAVER MEDICAL …          49          NA          75          44\n#&gt; 4 0749333730 CAPE PHYSICIANS…          67          84          85          65\n#&gt; 5 0840104360 ALLIANCE PHYSIC…          66          87          87          64\n#&gt; 6 0840109864 REX HOSPITAL INC          73          87          84          67\n#&gt; # ℹ 89 more rows\n#&gt; # ℹ 2 more variables: CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\nHow does pivot_wider() work?\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"B\",        \"bp1\",    140,\n  \"B\",        \"bp2\",    115, \n  \"A\",        \"bp2\",    120,\n  \"A\",        \"bp3\",    105\n)\n\nTake the values from the value column and the column names from the measurement column.\n\ndf |&gt; \n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n\n# A tibble: 2 × 4\n  id      bp1   bp2   bp3\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A       100   120   105\n2 B       140   115    NA\n\n#&gt; # A tibble: 2 × 4\n#&gt;   id      bp1   bp2   bp3\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A       100   120   105\n#&gt; 2 B       140   115    NA\n\nAny column that does not go into the names_from or values_from argument determines the number of rows. These are called the id_cols.\nWhat if we have duplicate values in the column giving the new column names and in the column giving the new value names? We get list-columns.\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"A\",        \"bp1\",    102,\n  \"A\",        \"bp2\",    120,\n  \"B\",        \"bp1\",    140, \n  \"B\",        \"bp2\",    115\n)\n\n\ndf |&gt;\n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n\nWarning: Values from `value` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(id, measurement)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\n# A tibble: 2 × 3\n  id    bp1       bp2      \n  &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\n#&gt; Warning: Values from `value` are not uniquely identified; output will contain\n#&gt; list-cols.\n#&gt; • Use `values_fn = list` to suppress this warning.\n#&gt; • Use `values_fn = {summary_fun}` to summarise duplicates.\n#&gt; • Use the following dplyr code to identify duplicates.\n#&gt;   {data} |&gt;\n#&gt;   dplyr::summarise(n = dplyr::n(), .by = c(id, measurement)) |&gt;\n#&gt;   dplyr::filter(n &gt; 1L)\n#&gt; # A tibble: 2 × 3\n#&gt;   id    bp1       bp2      \n#&gt;   &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n#&gt; 2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\nFollow the hint in the warning to locate the duplicate:\n\ndf |&gt; \n  group_by(id, measurement) |&gt; \n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n &gt; 1)\n\n# A tibble: 1 × 3\n  id    measurement     n\n  &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n1 A     bp1             2\n\n#&gt; # A tibble: 1 × 3\n#&gt;   id    measurement     n\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 A     bp1             2\n\n\ndf\n\n# A tibble: 5 × 3\n  id    measurement value\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 A     bp1           100\n2 A     bp1           102\n3 A     bp2           120\n4 B     bp1           140\n5 B     bp2           115"
  },
  {
    "objectID": "chapter_05_notes.html#lengthening-data",
    "href": "chapter_05_notes.html#lengthening-data",
    "title": "R for Data Science, 2nd Edition - Chapter 5 Notes",
    "section": "",
    "text": "Use pivot_longer().\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\"\n  )\n\n# A tibble: 24,092 × 5\n   artist track                   date.entered week   rank\n   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n 9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n# ℹ 24,082 more rows\n\n#&gt; # A tibble: 24,092 × 5\n#&gt;    artist track                   date.entered week   rank\n#&gt;    &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt;  1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt;  2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt;  3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt;  4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt;  5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt;  6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt;  7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7      99\n#&gt;  8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8      NA\n#&gt;  9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9      NA\n#&gt; 10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10     NA\n#&gt; # ℹ 24,082 more rows\n\n\ncols specifies which columns need to be pivoted, i.e. which columns aren’t variables. This argument uses the same syntax as select() so here we could use !c(artist, track, date.entered) or starts_with(\"wk\").\nnames_to names the variable stored in the column names, we named that variable week.\nvalues_to names the variable stored in the cell values, we named that variable rank.\n\nSo pivot_longer() starts with identifying which columns are variables, and which are not. For those columns that are not variables, we create a single variable capturing the names of these non-variable columns, and another variable capturing the values in the cells of those non-variable columns, which we must also name.\nSome NA values may be generated by the structure of the data set. This can be avoided with values_drop_na = TRUE.\n\nbillboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  )\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered week   rank\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87\n10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92\n# ℹ 5,297 more rows\n\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered week   rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#&gt; # ℹ 5,301 more rows\n\nThe values for week are characters. This is a good opportunity to use parse_number().\n\nbillboard_longer &lt;- billboard |&gt; \n  pivot_longer(\n    cols = starts_with(\"wk\"), \n    names_to = \"week\", \n    values_to = \"rank\",\n    values_drop_na = TRUE\n  ) |&gt; \n  mutate(\n    week = parse_number(week)\n  )\nbillboard_longer\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered  week  rank\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26       1    87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26       2    82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26       3    72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26       4    77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26       5    87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26       6    94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26       7    99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02       1    91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02       2    87\n10 2Ge+her The Hardest Part Of ... 2000-09-02       3    92\n# ℹ 5,297 more rows\n\n#&gt; # A tibble: 5,307 × 5\n#&gt;   artist track                   date.entered  week  rank\n#&gt;   &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26       1    87\n#&gt; 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26       2    82\n#&gt; 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26       3    72\n#&gt; 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26       4    77\n#&gt; 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26       5    87\n#&gt; 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26       6    94\n#&gt; # ℹ 5,301 more rows\n\nExamining pivot_longer()\n\ndf &lt;- tribble(\n  ~id,  ~bp1, ~bp2,\n   \"A\",  100,  120,\n   \"B\",  140,  115,\n   \"C\",  120,  125\n)\n\ndf |&gt; \n  pivot_longer(\n    cols = bp1:bp2,\n    names_to = \"measurement\",\n    values_to = \"value\"\n  )\n\n# A tibble: 6 × 3\n  id    measurement value\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 A     bp1           100\n2 A     bp2           120\n3 B     bp1           140\n4 B     bp2           115\n5 C     bp1           120\n6 C     bp2           125\n\n#&gt; # A tibble: 6 × 3\n#&gt;   id    measurement value\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 A     bp1           100\n#&gt; 2 A     bp2           120\n#&gt; 3 B     bp1           140\n#&gt; 4 B     bp2           115\n#&gt; 5 C     bp1           120\n#&gt; 6 C     bp2           125\n\nWhat if column names contain multiple pieces of information?\n\nwho2\n\n# A tibble: 7,240 × 58\n   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554 sp_m_5564\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan  1980       NA        NA        NA        NA        NA        NA\n 2 Afghanistan  1981       NA        NA        NA        NA        NA        NA\n 3 Afghanistan  1982       NA        NA        NA        NA        NA        NA\n 4 Afghanistan  1983       NA        NA        NA        NA        NA        NA\n 5 Afghanistan  1984       NA        NA        NA        NA        NA        NA\n 6 Afghanistan  1985       NA        NA        NA        NA        NA        NA\n 7 Afghanistan  1986       NA        NA        NA        NA        NA        NA\n 8 Afghanistan  1987       NA        NA        NA        NA        NA        NA\n 9 Afghanistan  1988       NA        NA        NA        NA        NA        NA\n10 Afghanistan  1989       NA        NA        NA        NA        NA        NA\n# ℹ 7,230 more rows\n# ℹ 50 more variables: sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, sp_f_1524 &lt;dbl&gt;,\n#   sp_f_2534 &lt;dbl&gt;, sp_f_3544 &lt;dbl&gt;, sp_f_4554 &lt;dbl&gt;, sp_f_5564 &lt;dbl&gt;,\n#   sp_f_65 &lt;dbl&gt;, sn_m_014 &lt;dbl&gt;, sn_m_1524 &lt;dbl&gt;, sn_m_2534 &lt;dbl&gt;,\n#   sn_m_3544 &lt;dbl&gt;, sn_m_4554 &lt;dbl&gt;, sn_m_5564 &lt;dbl&gt;, sn_m_65 &lt;dbl&gt;,\n#   sn_f_014 &lt;dbl&gt;, sn_f_1524 &lt;dbl&gt;, sn_f_2534 &lt;dbl&gt;, sn_f_3544 &lt;dbl&gt;,\n#   sn_f_4554 &lt;dbl&gt;, sn_f_5564 &lt;dbl&gt;, sn_f_65 &lt;dbl&gt;, ep_m_014 &lt;dbl&gt;, …\n\n#&gt; # A tibble: 7,240 × 58\n#&gt;   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980       NA        NA        NA        NA        NA\n#&gt; 2 Afghanistan  1981       NA        NA        NA        NA        NA\n#&gt; 3 Afghanistan  1982       NA        NA        NA        NA        NA\n#&gt; 4 Afghanistan  1983       NA        NA        NA        NA        NA\n#&gt; 5 Afghanistan  1984       NA        NA        NA        NA        NA\n#&gt; 6 Afghanistan  1985       NA        NA        NA        NA        NA\n#&gt; # ℹ 7,234 more rows\n#&gt; # ℹ 51 more variables: sp_m_5564 &lt;dbl&gt;, sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, …\n\nSo in this case we have six pieces of information recorded in who2: the country and the year (already columns); the method of diagnosis, the gender category, and the age range category (contained in the other column names); and the count of patients in that category (cell values).\n\nwho2 |&gt; \n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"), \n    names_sep = \"_\",\n    values_to = \"count\"\n  )\n\n# A tibble: 405,440 × 6\n   country      year diagnosis gender age   count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n 1 Afghanistan  1980 sp        m      014      NA\n 2 Afghanistan  1980 sp        m      1524     NA\n 3 Afghanistan  1980 sp        m      2534     NA\n 4 Afghanistan  1980 sp        m      3544     NA\n 5 Afghanistan  1980 sp        m      4554     NA\n 6 Afghanistan  1980 sp        m      5564     NA\n 7 Afghanistan  1980 sp        m      65       NA\n 8 Afghanistan  1980 sp        f      014      NA\n 9 Afghanistan  1980 sp        f      1524     NA\n10 Afghanistan  1980 sp        f      2534     NA\n# ℹ 405,430 more rows\n\n#&gt; # A tibble: 405,440 × 6\n#&gt;   country      year diagnosis gender age   count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan  1980 sp        m      014      NA\n#&gt; 2 Afghanistan  1980 sp        m      1524     NA\n#&gt; 3 Afghanistan  1980 sp        m      2534     NA\n#&gt; 4 Afghanistan  1980 sp        m      3544     NA\n#&gt; 5 Afghanistan  1980 sp        m      4554     NA\n#&gt; 6 Afghanistan  1980 sp        m      5564     NA\n#&gt; # ℹ 405,434 more rows\n\nWhat if the column names include a mix of of variable values and variable names?\n\nhousehold\n\n# A tibble: 5 × 5\n  family dob_child1 dob_child2 name_child1 name_child2\n   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      \n1      1 1998-11-26 2000-01-29 Susan       Jose       \n2      2 1996-06-22 NA         Mark        &lt;NA&gt;       \n3      3 2002-07-11 2004-04-05 Sam         Seth       \n4      4 2004-10-10 2009-08-27 Craig       Khai       \n5      5 2000-12-05 2005-02-28 Parker      Gracie     \n\n\nUse the .value sentinel value to indicate the first component of the pivoted column name as a variable name in the output. Note the lack of a values_to argument here. When you use .value in names_to, the column names in the input contribute to both values and variable names in the output.\n\nhousehold |&gt; \n  pivot_longer(\n    cols = !family, \n    names_to = c(\".value\", \"child\"), \n    names_sep = \"_\", \n    values_drop_na = TRUE\n  )\n\n# A tibble: 9 × 4\n  family child  dob        name  \n   &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt; \n1      1 child1 1998-11-26 Susan \n2      1 child2 2000-01-29 Jose  \n3      2 child1 1996-06-22 Mark  \n4      3 child1 2002-07-11 Sam   \n5      3 child2 2004-04-05 Seth  \n6      4 child1 2004-10-10 Craig \n7      4 child2 2009-08-27 Khai  \n8      5 child1 2000-12-05 Parker\n9      5 child2 2005-02-28 Gracie\n\n#&gt; # A tibble: 9 × 4\n#&gt;   family child  dob        name \n#&gt;    &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt;\n#&gt; 1      1 child1 1998-11-26 Susan\n#&gt; 2      1 child2 2000-01-29 Jose \n#&gt; 3      2 child1 1996-06-22 Mark \n#&gt; 4      3 child1 2002-07-11 Sam  \n#&gt; 5      3 child2 2004-04-05 Seth \n#&gt; 6      4 child1 2004-10-10 Craig\n#&gt; # ℹ 3 more rows"
  },
  {
    "objectID": "chapter_05_notes.html#widening-data",
    "href": "chapter_05_notes.html#widening-data",
    "title": "R for Data Science, 2nd Edition - Chapter 5 Notes",
    "section": "",
    "text": "Use pivot_wider() to increase columns and reduce rows.\n\ncms_patient_experience |&gt; \n  distinct(measure_cd, measure_title)\n\n# A tibble: 6 × 2\n  measure_cd   measure_title                                                    \n  &lt;chr&gt;        &lt;chr&gt;                                                            \n1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and Infor…\n2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate               \n3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider                 \n4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education               \n5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff           \n6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources             \n\n#&gt; # A tibble: 6 × 2\n#&gt;   measure_cd   measure_title                                                 \n#&gt;   &lt;chr&gt;        &lt;chr&gt;                                                         \n#&gt; 1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and In…\n#&gt; 2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate            \n#&gt; 3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider              \n#&gt; 4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education            \n#&gt; 5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff        \n#&gt; 6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources\n\npivot_wider() has the opposite interface to pivot_longer(): instead of choosing new column names, we need to provide the existing columns that define the values (values_from) and the column name (names_from):\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n\n# A tibble: 500 × 9\n   org_pac_id org_nm           measure_title CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3\n   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 0446157747 USC CARE MEDICA… CAHPS for MI…          63          NA          NA\n 2 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          87          NA\n 3 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          86\n 4 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          NA\n 5 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          NA\n 6 0446157747 USC CARE MEDICA… CAHPS for MI…          NA          NA          NA\n 7 0446162697 ASSOCIATION OF … CAHPS for MI…          59          NA          NA\n 8 0446162697 ASSOCIATION OF … CAHPS for MI…          NA          85          NA\n 9 0446162697 ASSOCIATION OF … CAHPS for MI…          NA          NA          83\n10 0446162697 ASSOCIATION OF … CAHPS for MI…          NA          NA          NA\n# ℹ 490 more rows\n# ℹ 3 more variables: CAHPS_GRP_5 &lt;dbl&gt;, CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\n#&gt; # A tibble: 500 × 9\n#&gt;   org_pac_id org_nm                   measure_title   CAHPS_GRP_1 CAHPS_GRP_2\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                    &lt;chr&gt;                 &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          63          NA\n#&gt; 2 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          87\n#&gt; 3 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 4 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 5 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; 6 0446157747 USC CARE MEDICAL GROUP … CAHPS for MIPS…          NA          NA\n#&gt; # ℹ 494 more rows\n#&gt; # ℹ 4 more variables: CAHPS_GRP_3 &lt;dbl&gt;, CAHPS_GRP_5 &lt;dbl&gt;, …\n\nIf you still have multiple rows per unit of interest, organization in this case, then the pivot_wider() didn’t work.\nThe problem is we need to tell pivot_wider() which column or columns have values that uniquely identify each row, in this case those are the variables starting with \"org\":\n\ncms_patient_experience |&gt; \n  pivot_wider(\n    id_cols = starts_with(\"org\"),\n    names_from = measure_cd,\n    values_from = prf_rate\n  )\n\n# A tibble: 95 × 8\n   org_pac_id org_nm CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5 CAHPS_GRP_8\n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 0446157747 USC C…          63          87          86          57          85\n 2 0446162697 ASSOC…          59          85          83          63          88\n 3 0547164295 BEAVE…          49          NA          75          44          73\n 4 0749333730 CAPE …          67          84          85          65          82\n 5 0840104360 ALLIA…          66          87          87          64          87\n 6 0840109864 REX H…          73          87          84          67          91\n 7 0840513552 SCL H…          58          83          76          58          78\n 8 0941545784 GRITM…          46          86          81          54          NA\n 9 1052612785 COMMU…          65          84          80          58          87\n10 1254237779 OUR L…          61          NA          NA          65          NA\n# ℹ 85 more rows\n# ℹ 1 more variable: CAHPS_GRP_12 &lt;dbl&gt;\n\n#&gt; # A tibble: 95 × 8\n#&gt;   org_pac_id org_nm           CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3 CAHPS_GRP_5\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 0446157747 USC CARE MEDICA…          63          87          86          57\n#&gt; 2 0446162697 ASSOCIATION OF …          59          85          83          63\n#&gt; 3 0547164295 BEAVER MEDICAL …          49          NA          75          44\n#&gt; 4 0749333730 CAPE PHYSICIANS…          67          84          85          65\n#&gt; 5 0840104360 ALLIANCE PHYSIC…          66          87          87          64\n#&gt; 6 0840109864 REX HOSPITAL INC          73          87          84          67\n#&gt; # ℹ 89 more rows\n#&gt; # ℹ 2 more variables: CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\nHow does pivot_wider() work?\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"B\",        \"bp1\",    140,\n  \"B\",        \"bp2\",    115, \n  \"A\",        \"bp2\",    120,\n  \"A\",        \"bp3\",    105\n)\n\nTake the values from the value column and the column names from the measurement column.\n\ndf |&gt; \n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n\n# A tibble: 2 × 4\n  id      bp1   bp2   bp3\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A       100   120   105\n2 B       140   115    NA\n\n#&gt; # A tibble: 2 × 4\n#&gt;   id      bp1   bp2   bp3\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A       100   120   105\n#&gt; 2 B       140   115    NA\n\nAny column that does not go into the names_from or values_from argument determines the number of rows. These are called the id_cols.\nWhat if we have duplicate values in the column giving the new column names and in the column giving the new value names? We get list-columns.\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"A\",        \"bp1\",    102,\n  \"A\",        \"bp2\",    120,\n  \"B\",        \"bp1\",    140, \n  \"B\",        \"bp2\",    115\n)\n\n\ndf |&gt;\n  pivot_wider(\n    names_from = measurement,\n    values_from = value\n  )\n\nWarning: Values from `value` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(id, measurement)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\n# A tibble: 2 × 3\n  id    bp1       bp2      \n  &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\n#&gt; Warning: Values from `value` are not uniquely identified; output will contain\n#&gt; list-cols.\n#&gt; • Use `values_fn = list` to suppress this warning.\n#&gt; • Use `values_fn = {summary_fun}` to summarise duplicates.\n#&gt; • Use the following dplyr code to identify duplicates.\n#&gt;   {data} |&gt;\n#&gt;   dplyr::summarise(n = dplyr::n(), .by = c(id, measurement)) |&gt;\n#&gt;   dplyr::filter(n &gt; 1L)\n#&gt; # A tibble: 2 × 3\n#&gt;   id    bp1       bp2      \n#&gt;   &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n#&gt; 2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\nFollow the hint in the warning to locate the duplicate:\n\ndf |&gt; \n  group_by(id, measurement) |&gt; \n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n &gt; 1)\n\n# A tibble: 1 × 3\n  id    measurement     n\n  &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n1 A     bp1             2\n\n#&gt; # A tibble: 1 × 3\n#&gt;   id    measurement     n\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 A     bp1             2\n\n\ndf\n\n# A tibble: 5 × 3\n  id    measurement value\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 A     bp1           100\n2 A     bp1           102\n3 A     bp2           120\n4 B     bp1           140\n5 B     bp2           115"
  },
  {
    "objectID": "chapter_12_notes.html",
    "href": "chapter_12_notes.html",
    "title": "R for Data Science, 2nd Edition - Chapter 12 Notes",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "chapter_26_notes.html",
    "href": "chapter_26_notes.html",
    "title": "R for Data Science, 2nd Edition - Chapter 26 Notes",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\nset.seed(1014)\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nHow to get medians of each column?\n\ndf |&gt; summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n\n# A tibble: 1 × 5\n      n      a      b       c     d\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1    10 -0.246 -0.287 -0.0567 0.144\n\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nUse across().\n\ndf |&gt; summarize(\n  n = n(),\n  across(a:d, median),\n)\n\n# A tibble: 1 × 5\n      n      a      b       c     d\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1    10 -0.246 -0.287 -0.0567 0.144\n\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nKey arguments: .cols, .fns, and you can use .names if you want to control names of output columns. if_any() and if_all() may be important within filter() calls.\n.cols can be supplied with the same syntax as select(), and everything() and where(). Use where() to select based on type.\n\nset.seed(1014)\ndf &lt;- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median))\n\n# A tibble: 2 × 5\n    grp      a      b       c       d\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 -0.244 -0.522 -0.0974 -0.251 \n2     2 -0.247  0.468  0.112   0.0700\n\n#&gt; # A tibble: 2 × 5\n#&gt;     grp      a      b       c       d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1     1 -0.244 -0.522 -0.0974 -0.251 \n#&gt; 2     2 -0.247  0.468  0.112   0.0700\n\nJust like other selectors, you can combine these with Boolean algebra. For example, !where(is.numeric) selects all non-numeric columns, and starts_with(\"a\") & where(is.logical) selects all logical columns whose name starts with “a”.\nCalling a single function.\nCalling multiple functions. (or multiple arguments). Here is an example of handling NA values in a call to median().\n\nset.seed(1014)\nrnorm_na &lt;- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss &lt;- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |&gt; \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n\n# A tibble: 1 × 5\n      a     b     c     d     n\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1    NA    NA    NA 0.413     5\n\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b     c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    NA    NA    NA 0.413     5\n\nWe need to create a new function that calls median() with the desired arguments:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\n# A tibble: 1 × 5\n       a      b      c     d     n\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 -0.703 -0.265 -0.522 0.413     5\n\n#&gt; # A tibble: 1 × 5\n#&gt;        a      b      c     d     n\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 -0.703 -0.265 -0.522 0.413     5\n\nThis is verbose, so we can use anonymous function syntax (\\(x) recommended over ~ .x).\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\n# A tibble: 1 × 5\n       a      b      c     d     n\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 -0.703 -0.265 -0.522 0.413     5\n\n\nIf you want to supply more than one function in the call to across(), use a named list:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n\n# A tibble: 1 × 9\n  a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss     n\n     &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n1   -0.703        1   -0.265        1   -0.522        2    0.413        0     5\n\n#&gt; # A tibble: 1 × 9\n#&gt;   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1   -0.703        1   -0.265        1   -0.522        2    0.413        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\nColumn names are specified with the .names argument.\n\ndf_miss |&gt; \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n\n# A tibble: 1 × 9\n  median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d     n\n     &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n1   -0.703        1   -0.265        1   -0.522        2    0.413        0     5\n\n#&gt; # A tibble: 1 × 9\n#&gt;   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1   -0.703        1   -0.265        1   -0.522        2    0.413        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\n.names is especially helpful when calling mutate() within across() to prevent overwriting columns, since the output of across() is given the same name as the inputs.\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n\n# A tibble: 5 × 4\n         a      b      c        d\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 -0.00557 -0.283 -1.86  -0.783  \n2  0.255   -0.247 -0.522 -0.00289\n3 -1.40    -0.554  0.512  0.413  \n4 -2.44    -0.244  0      0.724  \n5  0        0      0      2.35   \n\n#&gt; # A tibble: 5 × 4\n#&gt;          a      b      c        d\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 -0.00557 -0.283 -1.86  -0.783  \n#&gt; 2  0.255   -0.247 -0.522 -0.00289\n#&gt; 3 -1.40    -0.554  0.512  0.413  \n#&gt; 4 -2.44    -0.244  0      0.724  \n#&gt; 5  0        0      0      2.35\n\nUse the .names argument to instead create new columns.\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0), .names = \"{.col}_na_zero\")\n  )\n\n# A tibble: 5 × 8\n         a      b      c        d a_na_zero b_na_zero c_na_zero d_na_zero\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00557 -0.283 -1.86  -0.783    -0.00557    -0.283    -1.86   -0.783  \n2  0.255   -0.247 -0.522 -0.00289   0.255      -0.247    -0.522  -0.00289\n3 -1.40    -0.554  0.512  0.413    -1.40       -0.554     0.512   0.413  \n4 -2.44    -0.244 NA      0.724    -2.44       -0.244     0       0.724  \n5 NA       NA     NA      2.35      0           0         0       2.35   \n\n#&gt; # A tibble: 5 × 8\n#&gt;          a      b      c        d a_na_zero b_na_zero c_na_zero d_na_zero\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 -0.00557 -0.283 -1.86  -0.783    -0.00557    -0.283    -1.86   -0.783  \n#&gt; 2  0.255   -0.247 -0.522 -0.00289   0.255      -0.247    -0.522  -0.00289\n#&gt; 3 -1.40    -0.554  0.512  0.413    -1.40       -0.554     0.512   0.413  \n#&gt; 4 -2.44    -0.244 NA      0.724    -2.44       -0.244     0       0.724  \n#&gt; 5 NA       NA     NA      2.35      0           0         0       2.35\n\nFiltering. Two variants of across() are provided for use inside of filter(): if_any() and if_all()\n\n# same as df_miss |&gt; filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\ndf_miss |&gt; filter(if_any(a:d, is.na))\n\n# A tibble: 2 × 4\n      a      b     c     d\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 -2.44 -0.244    NA 0.724\n2 NA    NA        NA 2.35 \n\n#&gt; # A tibble: 2 × 4\n#&gt;       a      b     c     d\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 -2.44 -0.244    NA 0.724\n#&gt; 2 NA    NA        NA 2.35\n\n# same as df_miss |&gt; filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\ndf_miss |&gt; filter(if_all(a:d, is.na))\n\n# A tibble: 0 × 4\n# ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\nacross() can also be quite useful inside of functions.\nA helper function to expand all date columns into year, month, and day columns:\n\nexpand_dates &lt;- function(df) {\n  df |&gt; \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date &lt;- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |&gt; \n  expand_dates()\n\n# A tibble: 2 × 5\n  name  date       date_year date_month date_day\n  &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n1 Amy   2009-08-03      2009          8        3\n2 Bob   2010-01-16      2010          1       16\n\n#&gt; # A tibble: 2 × 5\n#&gt;   name  date       date_year date_month date_day\n#&gt;   &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 Amy   2009-08-03      2009          8        3\n#&gt; 2 Bob   2010-01-16      2010          1       16\n\nDon’t forget to use{ } when selecting columns inside of a function, since across() uses tidy-select.\n\nsummarize_means &lt;- function(df, summary_vars = where(is.numeric)) {\n  df |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means()\n\n# A tibble: 5 × 9\n  cut       carat depth table price     x     y     z     n\n  &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\n#&gt; # A tibble: 5 × 9\n#&gt;   cut       carat depth table price     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means(c(carat, x:z))\n\n# A tibble: 5 × 6\n  cut       carat     x     y     z     n\n  &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Fair      1.05   6.25  6.18  3.98  1610\n2 Good      0.849  5.84  5.85  3.64  4906\n3 Very Good 0.806  5.74  5.77  3.56 12082\n4 Premium   0.892  5.97  5.94  3.65 13791\n5 Ideal     0.703  5.51  5.52  3.40 21551\n\n#&gt; # A tibble: 5 × 6\n#&gt;   cut       carat     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  5.51  5.52  3.40 21551\n\nThere is a connection between across() and pivot_longer().\n\ndf |&gt; \n  summarize(across(a:d, list(median = median, mean = mean)))\n\n# A tibble: 1 × 8\n  a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\nCompare this to:\n\nlong &lt;- df |&gt; \n  pivot_longer(a:d) |&gt; \n  group_by(name) |&gt; \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n\n# A tibble: 4 × 3\n  name   median    mean\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 a     -0.246  -0.0426\n2 b      0.155  -0.0656\n3 c      0.0480 -0.0297\n4 d     -0.193  -0.200 \n\n#&gt; # A tibble: 4 × 3\n#&gt;   name   median    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 a     -0.246  -0.0426\n#&gt; 2 b      0.155  -0.0656\n#&gt; 3 c      0.0480 -0.0297\n#&gt; 4 d     -0.193  -0.200\n\nAnd to get it back to the structure across() gives you, pivot_wider()\n\nlong |&gt; \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n\n# A tibble: 1 × 8\n  a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\nThis is useful because occasionally you won’t be able to solve a problem with across(), such as groups of columns that you want to compute with simultaneously. Here is an example of a weighted mean:\n\nset.seed(1014)\ndf_paired &lt;- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n\nYou can do this with pivot_longer().\n\ndf_long &lt;- df_paired |&gt; \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n\n# A tibble: 40 × 3\n   group     val   wts\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 a     -1.40   0.290\n 2 b     -1.86   0.461\n 3 c      0.935  0.528\n 4 d      2.76   0.709\n 5 a      0.255  0.678\n 6 b     -0.522  0.315\n 7 c      0.176  0.601\n 8 d      0.0465 0.874\n 9 a     -2.44   0.735\n10 b     -0.0526 0.175\n# ℹ 30 more rows\n\n#&gt; # A tibble: 40 × 3\n#&gt;   group    val   wts\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 a     -1.40  0.290\n#&gt; 2 b     -1.86  0.461\n#&gt; 3 c      0.935 0.528\n#&gt; 4 d      2.76  0.709\n#&gt; 5 a      0.255 0.678\n#&gt; 6 b     -0.522 0.315\n#&gt; # ℹ 34 more rows\n\ndf_long |&gt; \n  group_by(group) |&gt; \n  summarize(mean = weighted.mean(val, wts))\n\n# A tibble: 4 × 2\n  group    mean\n  &lt;chr&gt;   &lt;dbl&gt;\n1 a     -0.207 \n2 b     -0.237 \n3 c      0.0208\n4 d      0.0655\n\n#&gt; # A tibble: 4 × 2\n#&gt;   group    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a     -0.207 \n#&gt; 2 b     -0.237 \n#&gt; 3 c      0.0208\n#&gt; 4 d      0.0655\n\nfind missing values after grouping on columns you choose.\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\nnycflights13::flights |&gt; show_missing(c(year, month, day))\n\n# A tibble: 365 × 9\n    year month   day dep_time dep_delay arr_time arr_delay tailnum air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;    &lt;int&gt;     &lt;int&gt;   &lt;int&gt;    &lt;int&gt;\n 1  2013     1     1        4         4        5        11       0       11\n 2  2013     1     2        8         8       10        15       2       15\n 3  2013     1     3       10        10       10        14       2       14\n 4  2013     1     4        6         6        6         7       2        7\n 5  2013     1     5        3         3        3         3       1        3\n 6  2013     1     6        1         1        1         3       0        3\n 7  2013     1     7        3         3        3         3       1        3\n 8  2013     1     8        4         4        4         7       1        7\n 9  2013     1     9        5         5        7         9       2        9\n10  2013     1    10        3         3        3         3       2        3\n# ℹ 355 more rows\n\n\n\n\n\nThe basic pattern is to use list.files(), then purrr:map(), then bind the rows together across elements of the list with purrr:list_bind().\n\n# \n# paths &lt;- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\n# paths\n#&gt;  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#&gt;  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#&gt;  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#&gt;  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#&gt;  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#&gt; [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\nNow use map().\n\n# files &lt;- map(paths, readxl::read_excel)\n# length(files)\n# #&gt; [1] 12\n# \n# files[[1]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 136 more rows\n\nNow combine elements of the list with purrr::list_rbind().\n\n# list_rbind(files)\n# #&gt; # A tibble: 1,704 × 5\n# #&gt;   country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1 Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2 Albania     Europe       55.2  1282697     1601.\n# #&gt; 3 Algeria     Africa       43.1  9279525     2449.\n# #&gt; 4 Angola      Africa       30.0  4232095     3521.\n# #&gt; 5 Argentina   Americas     62.5 17876956     5911.\n# #&gt; 6 Australia   Oceania      69.1  8691212    10040.\n# #&gt; # ℹ 1,698 more rows\n\n# Or we could do this:\n\n# paths |&gt; \n#   map(readxl::read_excel) |&gt; \n#   list_rbind()\n\nAdding additional arguments to the function being applied to each element of the list can be accomplished with an anonymous function.\n\n# paths |&gt; \n#   map(\\(path) readxl::read_excel(path, n_max = 1)) |&gt; \n#   list_rbind()\n# #&gt; # A tibble: 12 × 5\n# #&gt;   country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1 Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2 Afghanistan Asia         30.3  9240934      821.\n# #&gt; 3 Afghanistan Asia         32.0 10267083      853.\n# #&gt; 4 Afghanistan Asia         34.0 11537966      836.\n# #&gt; 5 Afghanistan Asia         36.1 13079460      740.\n# #&gt; 6 Afghanistan Asia         38.4 14880372      786.\n# #&gt; # ℹ 6 more rows\n\nWhat if variables are in the file names?\n\n# paths |&gt; set_names(basename) \n# #&gt;                  1952.xlsx                  1957.xlsx \n# #&gt; \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n# #&gt;                  1962.xlsx                  1967.xlsx \n# #&gt; \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n# #&gt;                  1972.xlsx                  1977.xlsx \n# #&gt; \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n# #&gt;                  1982.xlsx                  1987.xlsx \n# #&gt; \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n# #&gt;                  1992.xlsx                  1997.xlsx \n# #&gt; \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n# #&gt;                  2002.xlsx                  2007.xlsx \n# #&gt; \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n# \n# files &lt;- paths |&gt; \n#   set_names(basename) |&gt; \n#   map(readxl::read_excel)\n\n\n# paths |&gt; \n#   set_names(basename) |&gt; \n#   map(readxl::read_excel) |&gt; \n#   list_rbind(names_to = \"year\") |&gt; \n#   mutate(year = parse_number(year))\n# #&gt; # A tibble: 1,704 × 6\n# #&gt;    year country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1  1952 Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2  1952 Albania     Europe       55.2  1282697     1601.\n# #&gt; 3  1952 Algeria     Africa       43.1  9279525     2449.\n# #&gt; 4  1952 Angola      Africa       30.0  4232095     3521.\n# #&gt; 5  1952 Argentina   Americas     62.5 17876956     5911.\n# #&gt; 6  1952 Australia   Oceania      69.1  8691212    10040.\n# #&gt; # ℹ 1,698 more rows\n\nIn cases where there is more than one variable in the file name:\n\n# paths |&gt; \n#   set_names() |&gt; \n#   map(readxl::read_excel) |&gt; \n#   list_rbind(names_to = \"year\") |&gt; \n#   separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |&gt; \n#   separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n# #&gt; # A tibble: 1,704 × 8\n# #&gt;   dir       file  ext   country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n# #&gt; 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n# #&gt; 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n# #&gt; 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n# #&gt; 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n# #&gt; # ℹ 1,698 more rows\n\nThis all works if the data you get are already tidy, but in many cases this is not true. Then, it is useful to explore the structure of the data you have been given.\n\ndf_types &lt;- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder::gapminder)\n\n# A tibble: 6 × 3\n  col_name  col_type      n_miss\n  &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt;\n1 country   factor&lt;39935&gt;      0\n2 continent factor&lt;be586&gt;      0\n3 year      integer            0\n4 lifeExp   double             0\n5 pop       integer            0\n6 gdpPercap double             0\n\n#&gt; # A tibble: 6 × 3\n#&gt;   col_name  col_type  n_miss\n#&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 year      double         0\n#&gt; 2 country   character      0\n#&gt; 3 continent character      0\n#&gt; 4 lifeExp   double         0\n#&gt; 5 pop       double         0\n#&gt; 6 gdpPercap double         0\n\nTwo functions that may prove useful in modifying heterogenous files are map_if() and map_at().\nHandle failures in calls to map() with possibly().\n\n# \n# files &lt;- paths |&gt; \n#   map(possibly(\\(path) readxl::read_excel(path), NULL))\n# \n# data &lt;- files |&gt; list_rbind()\n# \n# # Now figure out which files failed.\n# \n# failed &lt;- map_vec(files, is.null)\n# paths[failed]\n# #&gt; character(0)\n\n\n\n\n\nSaving multiple data frames into one database.\nSaving multiple data frames into multiple .csv files.\nSaving multiple plots to multiple .png files.\n\nWriting to a database\nThe following would work if we just had .csv files.\n\n# con &lt;- DBI::dbConnect(duckdb::duckdb())\n# duckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\nWe actually have .xlsx files, so we’ll have to do this by hand. First, make a template.\n\n# template &lt;- readxl::read_excel(paths[[1]])\n# template$year &lt;- 1952\n# template\n# #&gt; # A tibble: 142 × 6\n# #&gt;   country     continent lifeExp      pop gdpPercap  year\n# #&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n# #&gt; 1 Afghanistan Asia         28.8  8425333      779.  1952\n# #&gt; 2 Albania     Europe       55.2  1282697     1601.  1952\n# #&gt; 3 Algeria     Africa       43.1  9279525     2449.  1952\n# #&gt; 4 Angola      Africa       30.0  4232095     3521.  1952\n# #&gt; 5 Argentina   Americas     62.5 17876956     5911.  1952\n# #&gt; 6 Australia   Oceania      69.1  8691212    10040.  1952\n# #&gt; # ℹ 136 more rows\n\nNow connect to the database, and create a database table with the template.\n\n# \n# con &lt;- DBI::dbConnect(duckdb::duckdb())\n# DBI::dbCreateTable(con, \"gapminder\", template)\n\nNow the table is created with the correct variable types, but no data are in the table.\n\n# con |&gt; tbl(\"gapminder\")\n# #&gt; # Source:   table&lt;gapminder&gt; [?? x 6]\n# #&gt; # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2/:memory:]\n# #&gt; # ℹ 6 variables: country &lt;chr&gt;, continent &lt;chr&gt;, lifeExp &lt;dbl&gt;, pop &lt;dbl&gt;,\n# #&gt; #   gdpPercap &lt;dbl&gt;, year &lt;dbl&gt;\n\nNow write a function that will read in files and append them to the database table:\n\n# append_file &lt;- function(path) {\n#   df &lt;- readxl::read_excel(path)\n#   df$year &lt;- parse_number(basename(path))\n#   \n#   DBI::dbAppendTable(con, \"gapminder\", df)\n# }\n\nWe don’t actually need the output of this function. So it’s a good time to use walk().\n\n# paths |&gt; walk(append_file)\n\n# con |&gt; \n#   tbl(\"gapminder\") |&gt; \n#   count(year)\n# #&gt; # Source:   SQL [?? x 2]\n# #&gt; # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2/:memory:]\n# #&gt;    year     n\n# #&gt;   &lt;dbl&gt; &lt;dbl&gt;\n# #&gt; 1  1952   142\n# #&gt; 2  1957   142\n# #&gt; 3  1962   142\n# #&gt; 4  1972   142\n# #&gt; 5  1982   142\n# #&gt; 6  1992   142\n# #&gt; # ℹ more rows\n\nWriting csv files. Here, they use group_nest to create a tibble per group.\n\nby_clarity &lt;- diamonds |&gt; \n  group_nest(clarity)\n\nby_clarity\n\n# A tibble: 8 × 2\n  clarity               data\n  &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n1 I1               [741 × 9]\n2 SI2            [9,194 × 9]\n3 SI1           [13,065 × 9]\n4 VS2           [12,258 × 9]\n5 VS1            [8,171 × 9]\n6 VVS2           [5,066 × 9]\n7 VVS1           [3,655 × 9]\n8 IF             [1,790 × 9]\n\n#&gt; # A tibble: 8 × 2\n#&gt;   clarity               data\n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n#&gt; 1 I1               [741 × 9]\n#&gt; 2 SI2            [9,194 × 9]\n#&gt; 3 SI1           [13,065 × 9]\n#&gt; 4 VS2           [12,258 × 9]\n#&gt; 5 VS1            [8,171 × 9]\n#&gt; 6 VVS2           [5,066 × 9]\n#&gt; # ℹ 2 more rows\n\n\nby_clarity$data[[1]]\n\n# A tibble: 741 × 9\n   carat cut       color depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n 7  1    Fair      G      66.4    59  2808  6.16  6.09  4.07\n 8  1.2  Fair      F      64.6    56  2809  6.73  6.66  4.33\n 9  0.43 Very Good E      58.4    62   555  4.94  5     2.9 \n10  1.02 Premium   G      60.3    58  2815  6.55  6.5   3.94\n# ℹ 731 more rows\n\n#&gt; # A tibble: 741 × 9\n#&gt;   carat cut       color depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#&gt; 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#&gt; 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#&gt; 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#&gt; 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#&gt; 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#&gt; # ℹ 735 more rows\n\nNow add a column with the name of the output file.\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n\n# A tibble: 8 × 3\n  clarity               data path             \n  &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n1 I1               [741 × 9] diamonds-I1.csv  \n2 SI2            [9,194 × 9] diamonds-SI2.csv \n3 SI1           [13,065 × 9] diamonds-SI1.csv \n4 VS2           [12,258 × 9] diamonds-VS2.csv \n5 VS1            [8,171 × 9] diamonds-VS1.csv \n6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n7 VVS1           [3,655 × 9] diamonds-VVS1.csv\n8 IF             [1,790 × 9] diamonds-IF.csv  \n\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity               data path             \n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n#&gt; 1 I1               [741 × 9] diamonds-I1.csv  \n#&gt; 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#&gt; 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#&gt; 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#&gt; 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#&gt; 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#&gt; # ℹ 2 more rows\n\nTo write each of these files to disk, we need to vary two arguments, the object and the path. That would be a good time to use map2(), but again, we care more about the side effect than the returned value, so use walk2() instead.\n\n# walk2(by_clarity$data, by_clarity$path, write_csv)\n\nSaving plots. Use the same basic approach.\n\ncarat_histogram &lt;- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\n\n\n\n\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\nNow use walk2() again:\n\n# walk2(\n#   by_clarity$path,\n#   by_clarity$plot,\n#   \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n# )\n\n\nby_clarity\n\n# A tibble: 8 × 4\n  clarity               data path             plot      \n  &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           &lt;list&gt;    \n1 I1               [741 × 9] clarity-I1.png   &lt;ggplt2::&gt;\n2 SI2            [9,194 × 9] clarity-SI2.png  &lt;ggplt2::&gt;\n3 SI1           [13,065 × 9] clarity-SI1.png  &lt;ggplt2::&gt;\n4 VS2           [12,258 × 9] clarity-VS2.png  &lt;ggplt2::&gt;\n5 VS1            [8,171 × 9] clarity-VS1.png  &lt;ggplt2::&gt;\n6 VVS2           [5,066 × 9] clarity-VVS2.png &lt;ggplt2::&gt;\n7 VVS1           [3,655 × 9] clarity-VVS1.png &lt;ggplt2::&gt;\n8 IF             [1,790 × 9] clarity-IF.png   &lt;ggplt2::&gt;"
  },
  {
    "objectID": "chapter_26_notes.html#modifying-multiple-columns",
    "href": "chapter_26_notes.html#modifying-multiple-columns",
    "title": "R for Data Science, 2nd Edition - Chapter 26 Notes",
    "section": "",
    "text": "set.seed(1014)\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nHow to get medians of each column?\n\ndf |&gt; summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n\n# A tibble: 1 × 5\n      n      a      b       c     d\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1    10 -0.246 -0.287 -0.0567 0.144\n\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nUse across().\n\ndf |&gt; summarize(\n  n = n(),\n  across(a:d, median),\n)\n\n# A tibble: 1 × 5\n      n      a      b       c     d\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1    10 -0.246 -0.287 -0.0567 0.144\n\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nKey arguments: .cols, .fns, and you can use .names if you want to control names of output columns. if_any() and if_all() may be important within filter() calls.\n.cols can be supplied with the same syntax as select(), and everything() and where(). Use where() to select based on type.\n\nset.seed(1014)\ndf &lt;- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median))\n\n# A tibble: 2 × 5\n    grp      a      b       c       d\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     1 -0.244 -0.522 -0.0974 -0.251 \n2     2 -0.247  0.468  0.112   0.0700\n\n#&gt; # A tibble: 2 × 5\n#&gt;     grp      a      b       c       d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1     1 -0.244 -0.522 -0.0974 -0.251 \n#&gt; 2     2 -0.247  0.468  0.112   0.0700\n\nJust like other selectors, you can combine these with Boolean algebra. For example, !where(is.numeric) selects all non-numeric columns, and starts_with(\"a\") & where(is.logical) selects all logical columns whose name starts with “a”.\nCalling a single function.\nCalling multiple functions. (or multiple arguments). Here is an example of handling NA values in a call to median().\n\nset.seed(1014)\nrnorm_na &lt;- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss &lt;- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |&gt; \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n\n# A tibble: 1 × 5\n      a     b     c     d     n\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1    NA    NA    NA 0.413     5\n\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b     c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    NA    NA    NA 0.413     5\n\nWe need to create a new function that calls median() with the desired arguments:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\n# A tibble: 1 × 5\n       a      b      c     d     n\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 -0.703 -0.265 -0.522 0.413     5\n\n#&gt; # A tibble: 1 × 5\n#&gt;        a      b      c     d     n\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 -0.703 -0.265 -0.522 0.413     5\n\nThis is verbose, so we can use anonymous function syntax (\\(x) recommended over ~ .x).\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\n# A tibble: 1 × 5\n       a      b      c     d     n\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 -0.703 -0.265 -0.522 0.413     5\n\n\nIf you want to supply more than one function in the call to across(), use a named list:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n\n# A tibble: 1 × 9\n  a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss     n\n     &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n1   -0.703        1   -0.265        1   -0.522        2    0.413        0     5\n\n#&gt; # A tibble: 1 × 9\n#&gt;   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1   -0.703        1   -0.265        1   -0.522        2    0.413        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\nColumn names are specified with the .names argument.\n\ndf_miss |&gt; \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n\n# A tibble: 1 × 9\n  median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d     n\n     &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt; &lt;int&gt;\n1   -0.703        1   -0.265        1   -0.522        2    0.413        0     5\n\n#&gt; # A tibble: 1 × 9\n#&gt;   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1   -0.703        1   -0.265        1   -0.522        2    0.413        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\n.names is especially helpful when calling mutate() within across() to prevent overwriting columns, since the output of across() is given the same name as the inputs.\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n\n# A tibble: 5 × 4\n         a      b      c        d\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 -0.00557 -0.283 -1.86  -0.783  \n2  0.255   -0.247 -0.522 -0.00289\n3 -1.40    -0.554  0.512  0.413  \n4 -2.44    -0.244  0      0.724  \n5  0        0      0      2.35   \n\n#&gt; # A tibble: 5 × 4\n#&gt;          a      b      c        d\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 -0.00557 -0.283 -1.86  -0.783  \n#&gt; 2  0.255   -0.247 -0.522 -0.00289\n#&gt; 3 -1.40    -0.554  0.512  0.413  \n#&gt; 4 -2.44    -0.244  0      0.724  \n#&gt; 5  0        0      0      2.35\n\nUse the .names argument to instead create new columns.\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0), .names = \"{.col}_na_zero\")\n  )\n\n# A tibble: 5 × 8\n         a      b      c        d a_na_zero b_na_zero c_na_zero d_na_zero\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00557 -0.283 -1.86  -0.783    -0.00557    -0.283    -1.86   -0.783  \n2  0.255   -0.247 -0.522 -0.00289   0.255      -0.247    -0.522  -0.00289\n3 -1.40    -0.554  0.512  0.413    -1.40       -0.554     0.512   0.413  \n4 -2.44    -0.244 NA      0.724    -2.44       -0.244     0       0.724  \n5 NA       NA     NA      2.35      0           0         0       2.35   \n\n#&gt; # A tibble: 5 × 8\n#&gt;          a      b      c        d a_na_zero b_na_zero c_na_zero d_na_zero\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 -0.00557 -0.283 -1.86  -0.783    -0.00557    -0.283    -1.86   -0.783  \n#&gt; 2  0.255   -0.247 -0.522 -0.00289   0.255      -0.247    -0.522  -0.00289\n#&gt; 3 -1.40    -0.554  0.512  0.413    -1.40       -0.554     0.512   0.413  \n#&gt; 4 -2.44    -0.244 NA      0.724    -2.44       -0.244     0       0.724  \n#&gt; 5 NA       NA     NA      2.35      0           0         0       2.35\n\nFiltering. Two variants of across() are provided for use inside of filter(): if_any() and if_all()\n\n# same as df_miss |&gt; filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\ndf_miss |&gt; filter(if_any(a:d, is.na))\n\n# A tibble: 2 × 4\n      a      b     c     d\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 -2.44 -0.244    NA 0.724\n2 NA    NA        NA 2.35 \n\n#&gt; # A tibble: 2 × 4\n#&gt;       a      b     c     d\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 -2.44 -0.244    NA 0.724\n#&gt; 2 NA    NA        NA 2.35\n\n# same as df_miss |&gt; filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\ndf_miss |&gt; filter(if_all(a:d, is.na))\n\n# A tibble: 0 × 4\n# ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\nacross() can also be quite useful inside of functions.\nA helper function to expand all date columns into year, month, and day columns:\n\nexpand_dates &lt;- function(df) {\n  df |&gt; \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date &lt;- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |&gt; \n  expand_dates()\n\n# A tibble: 2 × 5\n  name  date       date_year date_month date_day\n  &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n1 Amy   2009-08-03      2009          8        3\n2 Bob   2010-01-16      2010          1       16\n\n#&gt; # A tibble: 2 × 5\n#&gt;   name  date       date_year date_month date_day\n#&gt;   &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 Amy   2009-08-03      2009          8        3\n#&gt; 2 Bob   2010-01-16      2010          1       16\n\nDon’t forget to use{ } when selecting columns inside of a function, since across() uses tidy-select.\n\nsummarize_means &lt;- function(df, summary_vars = where(is.numeric)) {\n  df |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means()\n\n# A tibble: 5 × 9\n  cut       carat depth table price     x     y     z     n\n  &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\n#&gt; # A tibble: 5 × 9\n#&gt;   cut       carat depth table price     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means(c(carat, x:z))\n\n# A tibble: 5 × 6\n  cut       carat     x     y     z     n\n  &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Fair      1.05   6.25  6.18  3.98  1610\n2 Good      0.849  5.84  5.85  3.64  4906\n3 Very Good 0.806  5.74  5.77  3.56 12082\n4 Premium   0.892  5.97  5.94  3.65 13791\n5 Ideal     0.703  5.51  5.52  3.40 21551\n\n#&gt; # A tibble: 5 × 6\n#&gt;   cut       carat     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  5.51  5.52  3.40 21551\n\nThere is a connection between across() and pivot_longer().\n\ndf |&gt; \n  summarize(across(a:d, list(median = median, mean = mean)))\n\n# A tibble: 1 × 8\n  a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\nCompare this to:\n\nlong &lt;- df |&gt; \n  pivot_longer(a:d) |&gt; \n  group_by(name) |&gt; \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n\n# A tibble: 4 × 3\n  name   median    mean\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 a     -0.246  -0.0426\n2 b      0.155  -0.0656\n3 c      0.0480 -0.0297\n4 d     -0.193  -0.200 \n\n#&gt; # A tibble: 4 × 3\n#&gt;   name   median    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 a     -0.246  -0.0426\n#&gt; 2 b      0.155  -0.0656\n#&gt; 3 c      0.0480 -0.0297\n#&gt; 4 d     -0.193  -0.200\n\nAnd to get it back to the structure across() gives you, pivot_wider()\n\nlong |&gt; \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n\n# A tibble: 1 × 8\n  a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200\n\nThis is useful because occasionally you won’t be able to solve a problem with across(), such as groups of columns that you want to compute with simultaneously. Here is an example of a weighted mean:\n\nset.seed(1014)\ndf_paired &lt;- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n\nYou can do this with pivot_longer().\n\ndf_long &lt;- df_paired |&gt; \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n\n# A tibble: 40 × 3\n   group     val   wts\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 a     -1.40   0.290\n 2 b     -1.86   0.461\n 3 c      0.935  0.528\n 4 d      2.76   0.709\n 5 a      0.255  0.678\n 6 b     -0.522  0.315\n 7 c      0.176  0.601\n 8 d      0.0465 0.874\n 9 a     -2.44   0.735\n10 b     -0.0526 0.175\n# ℹ 30 more rows\n\n#&gt; # A tibble: 40 × 3\n#&gt;   group    val   wts\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 a     -1.40  0.290\n#&gt; 2 b     -1.86  0.461\n#&gt; 3 c      0.935 0.528\n#&gt; 4 d      2.76  0.709\n#&gt; 5 a      0.255 0.678\n#&gt; 6 b     -0.522 0.315\n#&gt; # ℹ 34 more rows\n\ndf_long |&gt; \n  group_by(group) |&gt; \n  summarize(mean = weighted.mean(val, wts))\n\n# A tibble: 4 × 2\n  group    mean\n  &lt;chr&gt;   &lt;dbl&gt;\n1 a     -0.207 \n2 b     -0.237 \n3 c      0.0208\n4 d      0.0655\n\n#&gt; # A tibble: 4 × 2\n#&gt;   group    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a     -0.207 \n#&gt; 2 b     -0.237 \n#&gt; 3 c      0.0208\n#&gt; 4 d      0.0655\n\nfind missing values after grouping on columns you choose.\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\nnycflights13::flights |&gt; show_missing(c(year, month, day))\n\n# A tibble: 365 × 9\n    year month   day dep_time dep_delay arr_time arr_delay tailnum air_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;    &lt;int&gt;     &lt;int&gt;   &lt;int&gt;    &lt;int&gt;\n 1  2013     1     1        4         4        5        11       0       11\n 2  2013     1     2        8         8       10        15       2       15\n 3  2013     1     3       10        10       10        14       2       14\n 4  2013     1     4        6         6        6         7       2        7\n 5  2013     1     5        3         3        3         3       1        3\n 6  2013     1     6        1         1        1         3       0        3\n 7  2013     1     7        3         3        3         3       1        3\n 8  2013     1     8        4         4        4         7       1        7\n 9  2013     1     9        5         5        7         9       2        9\n10  2013     1    10        3         3        3         3       2        3\n# ℹ 355 more rows"
  },
  {
    "objectID": "chapter_26_notes.html#reading-multiple-files",
    "href": "chapter_26_notes.html#reading-multiple-files",
    "title": "R for Data Science, 2nd Edition - Chapter 26 Notes",
    "section": "",
    "text": "The basic pattern is to use list.files(), then purrr:map(), then bind the rows together across elements of the list with purrr:list_bind().\n\n# \n# paths &lt;- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\n# paths\n#&gt;  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#&gt;  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#&gt;  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#&gt;  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#&gt;  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#&gt; [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\nNow use map().\n\n# files &lt;- map(paths, readxl::read_excel)\n# length(files)\n# #&gt; [1] 12\n# \n# files[[1]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 136 more rows\n\nNow combine elements of the list with purrr::list_rbind().\n\n# list_rbind(files)\n# #&gt; # A tibble: 1,704 × 5\n# #&gt;   country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1 Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2 Albania     Europe       55.2  1282697     1601.\n# #&gt; 3 Algeria     Africa       43.1  9279525     2449.\n# #&gt; 4 Angola      Africa       30.0  4232095     3521.\n# #&gt; 5 Argentina   Americas     62.5 17876956     5911.\n# #&gt; 6 Australia   Oceania      69.1  8691212    10040.\n# #&gt; # ℹ 1,698 more rows\n\n# Or we could do this:\n\n# paths |&gt; \n#   map(readxl::read_excel) |&gt; \n#   list_rbind()\n\nAdding additional arguments to the function being applied to each element of the list can be accomplished with an anonymous function.\n\n# paths |&gt; \n#   map(\\(path) readxl::read_excel(path, n_max = 1)) |&gt; \n#   list_rbind()\n# #&gt; # A tibble: 12 × 5\n# #&gt;   country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1 Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2 Afghanistan Asia         30.3  9240934      821.\n# #&gt; 3 Afghanistan Asia         32.0 10267083      853.\n# #&gt; 4 Afghanistan Asia         34.0 11537966      836.\n# #&gt; 5 Afghanistan Asia         36.1 13079460      740.\n# #&gt; 6 Afghanistan Asia         38.4 14880372      786.\n# #&gt; # ℹ 6 more rows\n\nWhat if variables are in the file names?\n\n# paths |&gt; set_names(basename) \n# #&gt;                  1952.xlsx                  1957.xlsx \n# #&gt; \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n# #&gt;                  1962.xlsx                  1967.xlsx \n# #&gt; \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n# #&gt;                  1972.xlsx                  1977.xlsx \n# #&gt; \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n# #&gt;                  1982.xlsx                  1987.xlsx \n# #&gt; \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n# #&gt;                  1992.xlsx                  1997.xlsx \n# #&gt; \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n# #&gt;                  2002.xlsx                  2007.xlsx \n# #&gt; \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n# \n# files &lt;- paths |&gt; \n#   set_names(basename) |&gt; \n#   map(readxl::read_excel)\n\n\n# paths |&gt; \n#   set_names(basename) |&gt; \n#   map(readxl::read_excel) |&gt; \n#   list_rbind(names_to = \"year\") |&gt; \n#   mutate(year = parse_number(year))\n# #&gt; # A tibble: 1,704 × 6\n# #&gt;    year country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1  1952 Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2  1952 Albania     Europe       55.2  1282697     1601.\n# #&gt; 3  1952 Algeria     Africa       43.1  9279525     2449.\n# #&gt; 4  1952 Angola      Africa       30.0  4232095     3521.\n# #&gt; 5  1952 Argentina   Americas     62.5 17876956     5911.\n# #&gt; 6  1952 Australia   Oceania      69.1  8691212    10040.\n# #&gt; # ℹ 1,698 more rows\n\nIn cases where there is more than one variable in the file name:\n\n# paths |&gt; \n#   set_names() |&gt; \n#   map(readxl::read_excel) |&gt; \n#   list_rbind(names_to = \"year\") |&gt; \n#   separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |&gt; \n#   separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n# #&gt; # A tibble: 1,704 × 8\n# #&gt;   dir       file  ext   country     continent lifeExp      pop gdpPercap\n# #&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n# #&gt; 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n# #&gt; 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n# #&gt; 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n# #&gt; 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n# #&gt; 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n# #&gt; 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n# #&gt; # ℹ 1,698 more rows\n\nThis all works if the data you get are already tidy, but in many cases this is not true. Then, it is useful to explore the structure of the data you have been given.\n\ndf_types &lt;- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder::gapminder)\n\n# A tibble: 6 × 3\n  col_name  col_type      n_miss\n  &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt;\n1 country   factor&lt;39935&gt;      0\n2 continent factor&lt;be586&gt;      0\n3 year      integer            0\n4 lifeExp   double             0\n5 pop       integer            0\n6 gdpPercap double             0\n\n#&gt; # A tibble: 6 × 3\n#&gt;   col_name  col_type  n_miss\n#&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 year      double         0\n#&gt; 2 country   character      0\n#&gt; 3 continent character      0\n#&gt; 4 lifeExp   double         0\n#&gt; 5 pop       double         0\n#&gt; 6 gdpPercap double         0\n\nTwo functions that may prove useful in modifying heterogenous files are map_if() and map_at().\nHandle failures in calls to map() with possibly().\n\n# \n# files &lt;- paths |&gt; \n#   map(possibly(\\(path) readxl::read_excel(path), NULL))\n# \n# data &lt;- files |&gt; list_rbind()\n# \n# # Now figure out which files failed.\n# \n# failed &lt;- map_vec(files, is.null)\n# paths[failed]\n# #&gt; character(0)"
  },
  {
    "objectID": "chapter_26_notes.html#saving-multiple-outputs",
    "href": "chapter_26_notes.html#saving-multiple-outputs",
    "title": "R for Data Science, 2nd Edition - Chapter 26 Notes",
    "section": "",
    "text": "Saving multiple data frames into one database.\nSaving multiple data frames into multiple .csv files.\nSaving multiple plots to multiple .png files.\n\nWriting to a database\nThe following would work if we just had .csv files.\n\n# con &lt;- DBI::dbConnect(duckdb::duckdb())\n# duckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\nWe actually have .xlsx files, so we’ll have to do this by hand. First, make a template.\n\n# template &lt;- readxl::read_excel(paths[[1]])\n# template$year &lt;- 1952\n# template\n# #&gt; # A tibble: 142 × 6\n# #&gt;   country     continent lifeExp      pop gdpPercap  year\n# #&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n# #&gt; 1 Afghanistan Asia         28.8  8425333      779.  1952\n# #&gt; 2 Albania     Europe       55.2  1282697     1601.  1952\n# #&gt; 3 Algeria     Africa       43.1  9279525     2449.  1952\n# #&gt; 4 Angola      Africa       30.0  4232095     3521.  1952\n# #&gt; 5 Argentina   Americas     62.5 17876956     5911.  1952\n# #&gt; 6 Australia   Oceania      69.1  8691212    10040.  1952\n# #&gt; # ℹ 136 more rows\n\nNow connect to the database, and create a database table with the template.\n\n# \n# con &lt;- DBI::dbConnect(duckdb::duckdb())\n# DBI::dbCreateTable(con, \"gapminder\", template)\n\nNow the table is created with the correct variable types, but no data are in the table.\n\n# con |&gt; tbl(\"gapminder\")\n# #&gt; # Source:   table&lt;gapminder&gt; [?? x 6]\n# #&gt; # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2/:memory:]\n# #&gt; # ℹ 6 variables: country &lt;chr&gt;, continent &lt;chr&gt;, lifeExp &lt;dbl&gt;, pop &lt;dbl&gt;,\n# #&gt; #   gdpPercap &lt;dbl&gt;, year &lt;dbl&gt;\n\nNow write a function that will read in files and append them to the database table:\n\n# append_file &lt;- function(path) {\n#   df &lt;- readxl::read_excel(path)\n#   df$year &lt;- parse_number(basename(path))\n#   \n#   DBI::dbAppendTable(con, \"gapminder\", df)\n# }\n\nWe don’t actually need the output of this function. So it’s a good time to use walk().\n\n# paths |&gt; walk(append_file)\n\n# con |&gt; \n#   tbl(\"gapminder\") |&gt; \n#   count(year)\n# #&gt; # Source:   SQL [?? x 2]\n# #&gt; # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2/:memory:]\n# #&gt;    year     n\n# #&gt;   &lt;dbl&gt; &lt;dbl&gt;\n# #&gt; 1  1952   142\n# #&gt; 2  1957   142\n# #&gt; 3  1962   142\n# #&gt; 4  1972   142\n# #&gt; 5  1982   142\n# #&gt; 6  1992   142\n# #&gt; # ℹ more rows\n\nWriting csv files. Here, they use group_nest to create a tibble per group.\n\nby_clarity &lt;- diamonds |&gt; \n  group_nest(clarity)\n\nby_clarity\n\n# A tibble: 8 × 2\n  clarity               data\n  &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n1 I1               [741 × 9]\n2 SI2            [9,194 × 9]\n3 SI1           [13,065 × 9]\n4 VS2           [12,258 × 9]\n5 VS1            [8,171 × 9]\n6 VVS2           [5,066 × 9]\n7 VVS1           [3,655 × 9]\n8 IF             [1,790 × 9]\n\n#&gt; # A tibble: 8 × 2\n#&gt;   clarity               data\n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n#&gt; 1 I1               [741 × 9]\n#&gt; 2 SI2            [9,194 × 9]\n#&gt; 3 SI1           [13,065 × 9]\n#&gt; 4 VS2           [12,258 × 9]\n#&gt; 5 VS1            [8,171 × 9]\n#&gt; 6 VVS2           [5,066 × 9]\n#&gt; # ℹ 2 more rows\n\n\nby_clarity$data[[1]]\n\n# A tibble: 741 × 9\n   carat cut       color depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n 7  1    Fair      G      66.4    59  2808  6.16  6.09  4.07\n 8  1.2  Fair      F      64.6    56  2809  6.73  6.66  4.33\n 9  0.43 Very Good E      58.4    62   555  4.94  5     2.9 \n10  1.02 Premium   G      60.3    58  2815  6.55  6.5   3.94\n# ℹ 731 more rows\n\n#&gt; # A tibble: 741 × 9\n#&gt;   carat cut       color depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#&gt; 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#&gt; 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#&gt; 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#&gt; 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#&gt; 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#&gt; # ℹ 735 more rows\n\nNow add a column with the name of the output file.\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n\n# A tibble: 8 × 3\n  clarity               data path             \n  &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n1 I1               [741 × 9] diamonds-I1.csv  \n2 SI2            [9,194 × 9] diamonds-SI2.csv \n3 SI1           [13,065 × 9] diamonds-SI1.csv \n4 VS2           [12,258 × 9] diamonds-VS2.csv \n5 VS1            [8,171 × 9] diamonds-VS1.csv \n6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n7 VVS1           [3,655 × 9] diamonds-VVS1.csv\n8 IF             [1,790 × 9] diamonds-IF.csv  \n\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity               data path             \n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n#&gt; 1 I1               [741 × 9] diamonds-I1.csv  \n#&gt; 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#&gt; 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#&gt; 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#&gt; 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#&gt; 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#&gt; # ℹ 2 more rows\n\nTo write each of these files to disk, we need to vary two arguments, the object and the path. That would be a good time to use map2(), but again, we care more about the side effect than the returned value, so use walk2() instead.\n\n# walk2(by_clarity$data, by_clarity$path, write_csv)\n\nSaving plots. Use the same basic approach.\n\ncarat_histogram &lt;- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\n\n\n\n\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\nNow use walk2() again:\n\n# walk2(\n#   by_clarity$path,\n#   by_clarity$plot,\n#   \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n# )\n\n\nby_clarity\n\n# A tibble: 8 × 4\n  clarity               data path             plot      \n  &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           &lt;list&gt;    \n1 I1               [741 × 9] clarity-I1.png   &lt;ggplt2::&gt;\n2 SI2            [9,194 × 9] clarity-SI2.png  &lt;ggplt2::&gt;\n3 SI1           [13,065 × 9] clarity-SI1.png  &lt;ggplt2::&gt;\n4 VS2           [12,258 × 9] clarity-VS2.png  &lt;ggplt2::&gt;\n5 VS1            [8,171 × 9] clarity-VS1.png  &lt;ggplt2::&gt;\n6 VVS2           [5,066 × 9] clarity-VVS2.png &lt;ggplt2::&gt;\n7 VVS1           [3,655 × 9] clarity-VVS1.png &lt;ggplt2::&gt;\n8 IF             [1,790 × 9] clarity-IF.png   &lt;ggplt2::&gt;"
  },
  {
    "objectID": "chapter_09_notes.html",
    "href": "chapter_09_notes.html",
    "title": "R for Data Science, 2nd Edition - Chapter 9 Notes",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.2\n✔ purrr     1.2.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point()\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, shape = class)) +\n  geom_point()\n\nWarning: The shape palette can deal with a maximum of 6 discrete values because more\nthan 6 becomes difficult to discriminate\nℹ you have requested 7 values. Consider specifying shapes manually if you need\n  that many of them.\n\n\nWarning: Removed 62 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n#&gt; Warning: The shape palette can deal with a maximum of 6 discrete values because more\n#&gt; than 6 becomes difficult to discriminate\n#&gt; ℹ you have requested 7 values. Consider specifying shapes manually if you\n#&gt;   need that many of them.\n#&gt; Warning: Removed 62 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy, size = class)) +\n  geom_point()\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n#&gt; Warning: Using size for a discrete variable is not advised.\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, alpha = class)) +\n  geom_point()\n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n#&gt; Warning: Using alpha for a discrete variable is not advised.\n\nArguments outside of aes() do not map onto variables to determine appearance.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(color = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nSame data, different geoms:\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nNot every aesthetic works with every geom. You can’t set the shape or a line geom.\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy, shape = drv)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, linetype = drv)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nInstead of giving a shape to a line geom, ggplot split the lines by drv.\nFor geoms that produce a single geometric object, you can use the group aesthetic to draw multiple objects. Note that the group aesthetic does not add a legend or distinguishing features to the geoms.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) + \n  geom_point() +\n  geom_smooth(aes(linetype = drv))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nPlacing mappings in a geom function overwrites the global mappings for that layer only. This means you can have different aesthetics in different layers.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(aes(color = class)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nYou can use this idea to specify different data for each layer.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    color = \"red\"\n  ) +\n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    shape = \"circle open\", size = 3, color = \"red\"\n  )\n\n\n\n\n\n\n\n\n\n# Left\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n# Middle\nggplot(mpg, aes(x = hwy)) +\n  geom_density()\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nfacet_wrap() splits a plot into subplots that each display one subset of the data based on a categorical variable.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_wrap(~cyl)\n\n\n\n\n\n\n\n\nTo facet with a combination of two variables, switch to facet_grid().\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl)\n\n\n\n\n\n\n\n\nLet the x and y axes vary across plots with scales = \"free\".\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl, scales = \"free\")\n\n\n\n\n\n\n\n\nUse the . to facet horizontally?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\n\n\n\n\n\n\n\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(drv ~ .)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_wrap(~drv)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() +\n  facet_grid(. ~ drv)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\nWhen new values have to be calculated for the plot.\n\nBar charts, histograms, and frequency polygons bin your data and then plot bin counts, the number of points that fall in each bin.\nSmoothers fit a model to your data and then plot predictions from the model.\nBoxplots compute the five-number summary of the distribution and then display that summary as a specially formatted box.\n\n\nggplot(diamonds, aes(x = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe algorithm used to calculate new values for a graph is called a stat, short for statistical transformation.\nYou can see which stat a geom uses by looking at default arguments, and the documentation for a given stat can be found on the geom help page. See how stat_count() is documented on the geom_bar() help page.\nEvery geom has a default stat, and every stat has a default geom.\nYou might need to use the stat explicitly to:\n\noverride the default stat\n\n\ndiamonds |&gt;\n  count(cut) |&gt;\n  ggplot(aes(x = cut, y = n)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\nOverride default mapping from transformed variables to aesthetics.\n\nFor example, a bar chart of proportions instead of counts is possible like this:\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop), group = 1)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\nYou might want to draw greater attention to the statistical transformation in your code. Here is an example with stat_summary(), which summarizes the y value for each unique x value plotted.\n\n\nggplot(diamonds) + \n  stat_summary(\n    aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )"
  },
  {
    "objectID": "chapter_09_notes.html#aesthetic-mappings",
    "href": "chapter_09_notes.html#aesthetic-mappings",
    "title": "R for Data Science, 2nd Edition - Chapter 9 Notes",
    "section": "",
    "text": "# Left\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point()\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, shape = class)) +\n  geom_point()\n\nWarning: The shape palette can deal with a maximum of 6 discrete values because more\nthan 6 becomes difficult to discriminate\nℹ you have requested 7 values. Consider specifying shapes manually if you need\n  that many of them.\n\n\nWarning: Removed 62 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n#&gt; Warning: The shape palette can deal with a maximum of 6 discrete values because more\n#&gt; than 6 becomes difficult to discriminate\n#&gt; ℹ you have requested 7 values. Consider specifying shapes manually if you\n#&gt;   need that many of them.\n#&gt; Warning: Removed 62 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy, size = class)) +\n  geom_point()\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n#&gt; Warning: Using size for a discrete variable is not advised.\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, alpha = class)) +\n  geom_point()\n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n#&gt; Warning: Using alpha for a discrete variable is not advised.\n\nArguments outside of aes() do not map onto variables to determine appearance.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(color = \"blue\")"
  },
  {
    "objectID": "chapter_09_notes.html#geometric-objects",
    "href": "chapter_09_notes.html#geometric-objects",
    "title": "R for Data Science, 2nd Edition - Chapter 9 Notes",
    "section": "",
    "text": "Same data, different geoms:\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nNot every aesthetic works with every geom. You can’t set the shape or a line geom.\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy, shape = drv)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, linetype = drv)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nInstead of giving a shape to a line geom, ggplot split the lines by drv.\nFor geoms that produce a single geometric object, you can use the group aesthetic to draw multiple objects. Note that the group aesthetic does not add a legend or distinguishing features to the geoms.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) + \n  geom_point() +\n  geom_smooth(aes(linetype = drv))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nPlacing mappings in a geom function overwrites the global mappings for that layer only. This means you can have different aesthetics in different layers.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(aes(color = class)) + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nYou can use this idea to specify different data for each layer.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    color = \"red\"\n  ) +\n  geom_point(\n    data = mpg |&gt; filter(class == \"2seater\"), \n    shape = \"circle open\", size = 3, color = \"red\"\n  )\n\n\n\n\n\n\n\n\n\n# Left\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram(binwidth = 2)\n\n\n\n\n\n\n\n# Middle\nggplot(mpg, aes(x = hwy)) +\n  geom_density()\n\n\n\n\n\n\n\n# Right\nggplot(mpg, aes(x = hwy)) +\n  geom_boxplot()"
  },
  {
    "objectID": "chapter_09_notes.html#facets",
    "href": "chapter_09_notes.html#facets",
    "title": "R for Data Science, 2nd Edition - Chapter 9 Notes",
    "section": "",
    "text": "facet_wrap() splits a plot into subplots that each display one subset of the data based on a categorical variable.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_wrap(~cyl)\n\n\n\n\n\n\n\n\nTo facet with a combination of two variables, switch to facet_grid().\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl)\n\n\n\n\n\n\n\n\nLet the x and y axes vary across plots with scales = \"free\".\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl, scales = \"free\")\n\n\n\n\n\n\n\n\nUse the . to facet horizontally?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\n\n\n\n\n\n\n\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(drv ~ .)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_wrap(~drv)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\n\n\n\n\n\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() +\n  facet_grid(. ~ drv)\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`."
  },
  {
    "objectID": "chapter_09_notes.html#statistical-transformations",
    "href": "chapter_09_notes.html#statistical-transformations",
    "title": "R for Data Science, 2nd Edition - Chapter 9 Notes",
    "section": "",
    "text": "When new values have to be calculated for the plot.\n\nBar charts, histograms, and frequency polygons bin your data and then plot bin counts, the number of points that fall in each bin.\nSmoothers fit a model to your data and then plot predictions from the model.\nBoxplots compute the five-number summary of the distribution and then display that summary as a specially formatted box.\n\n\nggplot(diamonds, aes(x = cut)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe algorithm used to calculate new values for a graph is called a stat, short for statistical transformation.\nYou can see which stat a geom uses by looking at default arguments, and the documentation for a given stat can be found on the geom help page. See how stat_count() is documented on the geom_bar() help page.\nEvery geom has a default stat, and every stat has a default geom.\nYou might need to use the stat explicitly to:\n\noverride the default stat\n\n\ndiamonds |&gt;\n  count(cut) |&gt;\n  ggplot(aes(x = cut, y = n)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\nOverride default mapping from transformed variables to aesthetics.\n\nFor example, a bar chart of proportions instead of counts is possible like this:\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop), group = 1)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\nYou might want to draw greater attention to the statistical transformation in your code. Here is an example with stat_summary(), which summarizes the y value for each unique x value plotted.\n\n\nggplot(diamonds) + \n  stat_summary(\n    aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )"
  }
]