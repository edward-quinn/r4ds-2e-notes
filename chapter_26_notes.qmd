---
title: "R for Data Science, 2nd Edition - Chapter 26 Notes"
freeze: true
format:
    html:
        toc: true
editor_options: 
  chunk_output_type: console
---

# 26 Iteration

```{r}

library(tidyverse)

```

## 26.2 Modifying multiple columns

```{r}

set.seed(1014)
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)


```

How to get medians of each column?

```{r}


df |> summarize(
  n = n(),
  a = median(a),
  b = median(b),
  c = median(c),
  d = median(d),
)
#> # A tibble: 1 × 5
#>       n      a      b       c     d
#>   <int>  <dbl>  <dbl>   <dbl> <dbl>
#> 1    10 -0.246 -0.287 -0.0567 0.144


```

Use `across()`.


```{r}


df |> summarize(
  n = n(),
  across(a:d, median),
)
#> # A tibble: 1 × 5
#>       n      a      b       c     d
#>   <int>  <dbl>  <dbl>   <dbl> <dbl>
#> 1    10 -0.246 -0.287 -0.0567 0.144

```

Key arguments: `.cols`, `.fns`, and you can use `.names` if you want to control names of output columns. `if_any()` and `if_all()` may be important within `filter()` calls.

`.cols` can be supplied with the same syntax as `select()`, and `everything()` and `where()`. Use `where()` to select based on type.

```{r}

set.seed(1014)
df <- tibble(
  grp = sample(2, 10, replace = TRUE),
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df |> 
  group_by(grp) |> 
  summarize(across(everything(), median))
#> # A tibble: 2 × 5
#>     grp      a      b       c       d
#>   <int>  <dbl>  <dbl>   <dbl>   <dbl>
#> 1     1 -0.244 -0.522 -0.0974 -0.251 
#> 2     2 -0.247  0.468  0.112   0.0700


```

Just like other selectors, you can combine these with Boolean algebra. For example, `!where(is.numeric)` selects all non-numeric columns, and `starts_with("a") & where(is.logical)` selects all logical columns whose name starts with “a”.

**Calling a single function**.

**Calling multiple functions**. (or multiple arguments). Here is an example of handling `NA` values in a call to `median()`.


```{r}

set.seed(1014)
rnorm_na <- function(n, n_na, mean = 0, sd = 1) {
  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))
}

df_miss <- tibble(
  a = rnorm_na(5, 1),
  b = rnorm_na(5, 1),
  c = rnorm_na(5, 2),
  d = rnorm(5)
)
df_miss |> 
  summarize(
    across(a:d, median),
    n = n()
  )
#> # A tibble: 1 × 5
#>       a     b     c     d     n
#>   <dbl> <dbl> <dbl> <dbl> <int>
#> 1    NA    NA    NA 0.413     5


```

We need to create a new function that calls `median()` with the desired arguments:


```{r}

df_miss |> 
  summarize(
    across(a:d, function(x) median(x, na.rm = TRUE)),
    n = n()
  )
#> # A tibble: 1 × 5
#>        a      b      c     d     n
#>    <dbl>  <dbl>  <dbl> <dbl> <int>
#> 1 -0.703 -0.265 -0.522 0.413     5


```


This is verbose, so we can use anonymous function syntax (`\(x)` recommended over `~ .x`).


```{r}

df_miss |> 
  summarize(
    across(a:d, \(x) median(x, na.rm = TRUE)),
    n = n()
  )


```

If you want to supply more than one function in the call to `across()`, use a named list:


```{r}

df_miss |> 
  summarize(
    across(a:d, list(
      median = \(x) median(x, na.rm = TRUE),
      n_miss = \(x) sum(is.na(x))
    )),
    n = n()
  )
#> # A tibble: 1 × 9
#>   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss
#>      <dbl>    <int>    <dbl>    <int>    <dbl>    <int>    <dbl>    <int>
#> 1   -0.703        1   -0.265        1   -0.522        2    0.413        0
#> # ℹ 1 more variable: n <int>


```


**Column names** are specified with the `.names` argument.


```{r}


df_miss |> 
  summarize(
    across(
      a:d,
      list(
        median = \(x) median(x, na.rm = TRUE),
        n_miss = \(x) sum(is.na(x))
      ),
      .names = "{.fn}_{.col}"
    ),
    n = n(),
  )
#> # A tibble: 1 × 9
#>   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d
#>      <dbl>    <int>    <dbl>    <int>    <dbl>    <int>    <dbl>    <int>
#> 1   -0.703        1   -0.265        1   -0.522        2    0.413        0
#> # ℹ 1 more variable: n <int>

```

`.names` is especially helpful when calling `mutate()` within `across()` to prevent overwriting columns, since the output of `across()` is given the same name as the inputs.


```{r}


df_miss |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0))
  )
#> # A tibble: 5 × 4
#>          a      b      c        d
#>      <dbl>  <dbl>  <dbl>    <dbl>
#> 1 -0.00557 -0.283 -1.86  -0.783  
#> 2  0.255   -0.247 -0.522 -0.00289
#> 3 -1.40    -0.554  0.512  0.413  
#> 4 -2.44    -0.244  0      0.724  
#> 5  0        0      0      2.35

```

Use the `.names` argument to instead create new columns.


```{r}


df_miss |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0), .names = "{.col}_na_zero")
  )
#> # A tibble: 5 × 8
#>          a      b      c        d a_na_zero b_na_zero c_na_zero d_na_zero
#>      <dbl>  <dbl>  <dbl>    <dbl>     <dbl>     <dbl>     <dbl>     <dbl>
#> 1 -0.00557 -0.283 -1.86  -0.783    -0.00557    -0.283    -1.86   -0.783  
#> 2  0.255   -0.247 -0.522 -0.00289   0.255      -0.247    -0.522  -0.00289
#> 3 -1.40    -0.554  0.512  0.413    -1.40       -0.554     0.512   0.413  
#> 4 -2.44    -0.244 NA      0.724    -2.44       -0.244     0       0.724  
#> 5 NA       NA     NA      2.35      0           0         0       2.35

```


**Filtering**. Two variants of `across()` are provided for use inside of `filter()`: `if_any()` and `if_all()` 



```{r}

# same as df_miss |> filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))
df_miss |> filter(if_any(a:d, is.na))
#> # A tibble: 2 × 4
#>       a      b     c     d
#>   <dbl>  <dbl> <dbl> <dbl>
#> 1 -2.44 -0.244    NA 0.724
#> 2 NA    NA        NA 2.35

# same as df_miss |> filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))
df_miss |> filter(if_all(a:d, is.na))
#> # A tibble: 0 × 4
#> # ℹ 4 variables: a <dbl>, b <dbl>, c <dbl>, d <dbl>


```

`across()` can also be quite useful inside of functions.

A helper function to expand all date columns into year, month, and day columns:

```{r}

expand_dates <- function(df) {
  df |> 
    mutate(
      across(where(is.Date), list(year = year, month = month, day = mday))
    )
}

df_date <- tibble(
  name = c("Amy", "Bob"),
  date = ymd(c("2009-08-03", "2010-01-16"))
)

df_date |> 
  expand_dates()
#> # A tibble: 2 × 5
#>   name  date       date_year date_month date_day
#>   <chr> <date>         <dbl>      <dbl>    <int>
#> 1 Amy   2009-08-03      2009          8        3
#> 2 Bob   2010-01-16      2010          1       16


```


Don't forget to use`{{ }}` when selecting columns inside of a function, since `across()` uses tidy-select.


```{r}

summarize_means <- function(df, summary_vars = where(is.numeric)) {
  df |> 
    summarize(
      across({{ summary_vars }}, \(x) mean(x, na.rm = TRUE)),
      n = n(),
      .groups = "drop"
    )
}

diamonds |> 
  group_by(cut) |> 
  summarize_means()
#> # A tibble: 5 × 9
#>   cut       carat depth table price     x     y     z     n
#>   <ord>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int>
#> 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610
#> 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906
#> 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082
#> 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791
#> 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551

diamonds |> 
  group_by(cut) |> 
  summarize_means(c(carat, x:z))
#> # A tibble: 5 × 6
#>   cut       carat     x     y     z     n
#>   <ord>     <dbl> <dbl> <dbl> <dbl> <int>
#> 1 Fair      1.05   6.25  6.18  3.98  1610
#> 2 Good      0.849  5.84  5.85  3.64  4906
#> 3 Very Good 0.806  5.74  5.77  3.56 12082
#> 4 Premium   0.892  5.97  5.94  3.65 13791
#> 5 Ideal     0.703  5.51  5.52  3.40 21551


```


There is a connection between `across()` and `pivot_longer()`.


```{r}

df |> 
  summarize(across(a:d, list(median = median, mean = mean)))
#> # A tibble: 1 × 8
#>   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean
#>      <dbl>   <dbl>    <dbl>   <dbl>    <dbl>   <dbl>    <dbl>  <dbl>
#> 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200


```

Compare this to:

```{r}


long <- df |> 
  pivot_longer(a:d) |> 
  group_by(name) |> 
  summarize(
    median = median(value),
    mean = mean(value)
  )
long
#> # A tibble: 4 × 3
#>   name   median    mean
#>   <chr>   <dbl>   <dbl>
#> 1 a     -0.246  -0.0426
#> 2 b      0.155  -0.0656
#> 3 c      0.0480 -0.0297
#> 4 d     -0.193  -0.200

```

And to get it back to the structure `across()` gives you, `pivot_wider()`

```{r}

long |> 
  pivot_wider(
    names_from = name,
    values_from = c(median, mean),
    names_vary = "slowest",
    names_glue = "{name}_{.value}"
  )
#> # A tibble: 1 × 8
#>   a_median  a_mean b_median  b_mean c_median  c_mean d_median d_mean
#>      <dbl>   <dbl>    <dbl>   <dbl>    <dbl>   <dbl>    <dbl>  <dbl>
#> 1   -0.246 -0.0426    0.155 -0.0656   0.0480 -0.0297   -0.193 -0.200


```


This is useful because occasionally you won't be able to solve a problem with `across()`, such as groups of columns that you want to compute with simultaneously. Here is an example of a weighted mean:


```{r}


set.seed(1014)
df_paired <- tibble(
  a_val = rnorm(10),
  a_wts = runif(10),
  b_val = rnorm(10),
  b_wts = runif(10),
  c_val = rnorm(10),
  c_wts = runif(10),
  d_val = rnorm(10),
  d_wts = runif(10)
)


```

You can do this with `pivot_longer()`.


```{r}

df_long <- df_paired |> 
  pivot_longer(
    everything(), 
    names_to = c("group", ".value"), 
    names_sep = "_"
  )
df_long
#> # A tibble: 40 × 3
#>   group    val   wts
#>   <chr>  <dbl> <dbl>
#> 1 a     -1.40  0.290
#> 2 b     -1.86  0.461
#> 3 c      0.935 0.528
#> 4 d      2.76  0.709
#> 5 a      0.255 0.678
#> 6 b     -0.522 0.315
#> # ℹ 34 more rows

df_long |> 
  group_by(group) |> 
  summarize(mean = weighted.mean(val, wts))
#> # A tibble: 4 × 2
#>   group    mean
#>   <chr>   <dbl>
#> 1 a     -0.207 
#> 2 b     -0.237 
#> 3 c      0.0208
#> 4 d      0.0655


```

find missing values after grouping on columns you choose.


```{r}


show_missing <- function(df, group_vars, summary_vars = everything()) {
  df |> 
    group_by(pick({{ group_vars }})) |> 
    summarize(
      across({{ summary_vars }}, \(x) sum(is.na(x))),
      .groups = "drop"
    ) |>
    select(where(\(x) any(x > 0)))
}
nycflights13::flights |> show_missing(c(year, month, day))


```



## 26.3 Reading multiple files


The basic pattern is to use `list.files()`, then `purrr:map()`, then bind the rows together across elements of the list with `purrr:list_bind()`.


```{r}
# 
# paths <- list.files("data/gapminder", pattern = "[.]xlsx$", full.names = TRUE)
# paths
#>  [1] "data/gapminder/1952.xlsx" "data/gapminder/1957.xlsx"
#>  [3] "data/gapminder/1962.xlsx" "data/gapminder/1967.xlsx"
#>  [5] "data/gapminder/1972.xlsx" "data/gapminder/1977.xlsx"
#>  [7] "data/gapminder/1982.xlsx" "data/gapminder/1987.xlsx"
#>  [9] "data/gapminder/1992.xlsx" "data/gapminder/1997.xlsx"
#> [11] "data/gapminder/2002.xlsx" "data/gapminder/2007.xlsx"


```

Now use `map()`.

```{r}

# files <- map(paths, readxl::read_excel)
# length(files)
# #> [1] 12
# 
# files[[1]]
#> # A tibble: 142 × 5
#>   country     continent lifeExp      pop gdpPercap
#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>
#> 1 Afghanistan Asia         28.8  8425333      779.
#> 2 Albania     Europe       55.2  1282697     1601.
#> 3 Algeria     Africa       43.1  9279525     2449.
#> 4 Angola      Africa       30.0  4232095     3521.
#> 5 Argentina   Americas     62.5 17876956     5911.
#> 6 Australia   Oceania      69.1  8691212    10040.
#> # ℹ 136 more rows


```

Now combine elements of the list with `purrr::list_rbind()`.

```{r}

# list_rbind(files)
# #> # A tibble: 1,704 × 5
# #>   country     continent lifeExp      pop gdpPercap
# #>   <chr>       <chr>       <dbl>    <dbl>     <dbl>
# #> 1 Afghanistan Asia         28.8  8425333      779.
# #> 2 Albania     Europe       55.2  1282697     1601.
# #> 3 Algeria     Africa       43.1  9279525     2449.
# #> 4 Angola      Africa       30.0  4232095     3521.
# #> 5 Argentina   Americas     62.5 17876956     5911.
# #> 6 Australia   Oceania      69.1  8691212    10040.
# #> # ℹ 1,698 more rows

# Or we could do this:

# paths |> 
#   map(readxl::read_excel) |> 
#   list_rbind()


```

Adding additional arguments to the function being applied to each element of the list can be accomplished with an anonymous function.

```{r}

# paths |> 
#   map(\(path) readxl::read_excel(path, n_max = 1)) |> 
#   list_rbind()
# #> # A tibble: 12 × 5
# #>   country     continent lifeExp      pop gdpPercap
# #>   <chr>       <chr>       <dbl>    <dbl>     <dbl>
# #> 1 Afghanistan Asia         28.8  8425333      779.
# #> 2 Afghanistan Asia         30.3  9240934      821.
# #> 3 Afghanistan Asia         32.0 10267083      853.
# #> 4 Afghanistan Asia         34.0 11537966      836.
# #> 5 Afghanistan Asia         36.1 13079460      740.
# #> 6 Afghanistan Asia         38.4 14880372      786.
# #> # ℹ 6 more rows


```

What if variables are in the file names?


```{r}

# paths |> set_names(basename) 
# #>                  1952.xlsx                  1957.xlsx 
# #> "data/gapminder/1952.xlsx" "data/gapminder/1957.xlsx" 
# #>                  1962.xlsx                  1967.xlsx 
# #> "data/gapminder/1962.xlsx" "data/gapminder/1967.xlsx" 
# #>                  1972.xlsx                  1977.xlsx 
# #> "data/gapminder/1972.xlsx" "data/gapminder/1977.xlsx" 
# #>                  1982.xlsx                  1987.xlsx 
# #> "data/gapminder/1982.xlsx" "data/gapminder/1987.xlsx" 
# #>                  1992.xlsx                  1997.xlsx 
# #> "data/gapminder/1992.xlsx" "data/gapminder/1997.xlsx" 
# #>                  2002.xlsx                  2007.xlsx 
# #> "data/gapminder/2002.xlsx" "data/gapminder/2007.xlsx"
# 
# files <- paths |> 
#   set_names(basename) |> 
#   map(readxl::read_excel)


```



```{r}

# paths |> 
#   set_names(basename) |> 
#   map(readxl::read_excel) |> 
#   list_rbind(names_to = "year") |> 
#   mutate(year = parse_number(year))
# #> # A tibble: 1,704 × 6
# #>    year country     continent lifeExp      pop gdpPercap
# #>   <dbl> <chr>       <chr>       <dbl>    <dbl>     <dbl>
# #> 1  1952 Afghanistan Asia         28.8  8425333      779.
# #> 2  1952 Albania     Europe       55.2  1282697     1601.
# #> 3  1952 Algeria     Africa       43.1  9279525     2449.
# #> 4  1952 Angola      Africa       30.0  4232095     3521.
# #> 5  1952 Argentina   Americas     62.5 17876956     5911.
# #> 6  1952 Australia   Oceania      69.1  8691212    10040.
# #> # ℹ 1,698 more rows


```


In cases where there is more than one variable in the file name:


```{r}


# paths |> 
#   set_names() |> 
#   map(readxl::read_excel) |> 
#   list_rbind(names_to = "year") |> 
#   separate_wider_delim(year, delim = "/", names = c(NA, "dir", "file")) |> 
#   separate_wider_delim(file, delim = ".", names = c("file", "ext"))
# #> # A tibble: 1,704 × 8
# #>   dir       file  ext   country     continent lifeExp      pop gdpPercap
# #>   <chr>     <chr> <chr> <chr>       <chr>       <dbl>    <dbl>     <dbl>
# #> 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.
# #> 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.
# #> 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.
# #> 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.
# #> 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.
# #> 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.
# #> # ℹ 1,698 more rows


```

This all works if the data you get are already tidy, but in many cases this is not true. Then, it is useful to explore the structure of the data you have been given.


```{r}

df_types <- function(df) {
  tibble(
    col_name = names(df), 
    col_type = map_chr(df, vctrs::vec_ptype_full),
    n_miss = map_int(df, \(x) sum(is.na(x)))
  )
}

df_types(gapminder::gapminder)
#> # A tibble: 6 × 3
#>   col_name  col_type  n_miss
#>   <chr>     <chr>      <int>
#> 1 year      double         0
#> 2 country   character      0
#> 3 continent character      0
#> 4 lifeExp   double         0
#> 5 pop       double         0
#> 6 gdpPercap double         0


```

Two functions that may prove useful in modifying heterogenous files are `map_if()` and `map_at()`.  

Handle failures in calls to `map()` with `possibly()`.


```{r}

# 
# files <- paths |> 
#   map(possibly(\(path) readxl::read_excel(path), NULL))
# 
# data <- files |> list_rbind()
# 
# # Now figure out which files failed.
# 
# failed <- map_vec(files, is.null)
# paths[failed]
# #> character(0)


```



## 26.4 Saving multiple outputs

-   Saving multiple data frames into one database.
-   Saving multiple data frames into multiple .csv files.
-   Saving multiple plots to multiple .png files.


**Writing to a database**

The following would work if we just had `.csv` files.

```{r}


# con <- DBI::dbConnect(duckdb::duckdb())
# duckdb::duckdb_read_csv(con, "gapminder", paths)

```

We actually have `.xlsx` files, so we'll have to do this by hand. First, make a template.

```{r}

# template <- readxl::read_excel(paths[[1]])
# template$year <- 1952
# template
# #> # A tibble: 142 × 6
# #>   country     continent lifeExp      pop gdpPercap  year
# #>   <chr>       <chr>       <dbl>    <dbl>     <dbl> <dbl>
# #> 1 Afghanistan Asia         28.8  8425333      779.  1952
# #> 2 Albania     Europe       55.2  1282697     1601.  1952
# #> 3 Algeria     Africa       43.1  9279525     2449.  1952
# #> 4 Angola      Africa       30.0  4232095     3521.  1952
# #> 5 Argentina   Americas     62.5 17876956     5911.  1952
# #> 6 Australia   Oceania      69.1  8691212    10040.  1952
# #> # ℹ 136 more rows


```

Now connect to the database, and create a database table with the template.


```{r}
# 
# con <- DBI::dbConnect(duckdb::duckdb())
# DBI::dbCreateTable(con, "gapminder", template)


```

Now the table is created with the correct variable types, but no data are in the table.

```{r}


# con |> tbl("gapminder")
# #> # Source:   table<gapminder> [?? x 6]
# #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2/:memory:]
# #> # ℹ 6 variables: country <chr>, continent <chr>, lifeExp <dbl>, pop <dbl>,
# #> #   gdpPercap <dbl>, year <dbl>


```


Now write a function that will read in files and append them to the database table:


```{r}


# append_file <- function(path) {
#   df <- readxl::read_excel(path)
#   df$year <- parse_number(basename(path))
#   
#   DBI::dbAppendTable(con, "gapminder", df)
# }


```

We don't actually need the output of this function. So it's a good time to use `walk()`.


```{r}


# paths |> walk(append_file)

# con |> 
#   tbl("gapminder") |> 
#   count(year)
# #> # Source:   SQL [?? x 2]
# #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2/:memory:]
# #>    year     n
# #>   <dbl> <dbl>
# #> 1  1952   142
# #> 2  1957   142
# #> 3  1962   142
# #> 4  1972   142
# #> 5  1982   142
# #> 6  1992   142
# #> # ℹ more rows

```


**Writing csv files**. Here, they use `group_nest` to create a tibble per group.


```{r}

by_clarity <- diamonds |> 
  group_nest(clarity)

by_clarity
#> # A tibble: 8 × 2
#>   clarity               data
#>   <ord>   <list<tibble[,9]>>
#> 1 I1               [741 × 9]
#> 2 SI2            [9,194 × 9]
#> 3 SI1           [13,065 × 9]
#> 4 VS2           [12,258 × 9]
#> 5 VS1            [8,171 × 9]
#> 6 VVS2           [5,066 × 9]
#> # ℹ 2 more rows


```


```{r}

by_clarity$data[[1]]
#> # A tibble: 741 × 9
#>   carat cut       color depth table price     x     y     z
#>   <dbl> <ord>     <ord> <dbl> <dbl> <int> <dbl> <dbl> <dbl>
#> 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68
#> 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13
#> 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94
#> 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03
#> 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88
#> 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   
#> # ℹ 735 more rows


```


Now add a column with the name of the output file.


```{r}

by_clarity <- by_clarity |> 
  mutate(path = str_glue("diamonds-{clarity}.csv"))

by_clarity
#> # A tibble: 8 × 3
#>   clarity               data path             
#>   <ord>   <list<tibble[,9]>> <glue>           
#> 1 I1               [741 × 9] diamonds-I1.csv  
#> 2 SI2            [9,194 × 9] diamonds-SI2.csv 
#> 3 SI1           [13,065 × 9] diamonds-SI1.csv 
#> 4 VS2           [12,258 × 9] diamonds-VS2.csv 
#> 5 VS1            [8,171 × 9] diamonds-VS1.csv 
#> 6 VVS2           [5,066 × 9] diamonds-VVS2.csv
#> # ℹ 2 more rows


```


To write each of these files to disk, we need to vary two arguments, the object and the path. That would be a good time to use `map2()`, but again, we care more about the side effect than the returned value, so use `walk2()` instead.

```{r}


# walk2(by_clarity$data, by_clarity$path, write_csv)

```



**Saving plots**. Use the same basic approach.



```{r}


carat_histogram <- function(df) {
  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  
}

carat_histogram(by_clarity$data[[1]])

```




```{r}

by_clarity <- by_clarity |> 
  mutate(
    plot = map(data, carat_histogram),
    path = str_glue("clarity-{clarity}.png")
  )


```

Now use `walk2()` again:



```{r}

# walk2(
#   by_clarity$path,
#   by_clarity$plot,
#   \(path, plot) ggsave(path, plot, width = 6, height = 6)
# )


```

```{r}

by_clarity

```

